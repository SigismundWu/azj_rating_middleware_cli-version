{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1004,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas.tseries.offsets import *\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import math\n",
    "from copy import deepcopy\n",
    "import json\n",
    "from itertools import combinations, permutations\n",
    "\n",
    "% matplotlib inline\n",
    "pd.set_option('max_columns', 100)\n",
    "pd.set_option('max_rows', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1005,
   "metadata": {},
   "outputs": [],
   "source": [
    "def teacher_qc_score(start_time, end_time, df_qc, class_type_name_special, hq_name_special):\n",
    "    # 筛选条件\n",
    "    df_qc = df_qc.loc[(~df_qc['class_type_name'].isin(class_type_name_special)) & \n",
    "                    (~df_qc['hq_name'].isin(hq_name_special)) & \n",
    "                    (df_qc['start_time'] >= start_time) & (df_qc['end_time'] <= end_time)]\n",
    "    # log score-mean\n",
    "    df_qc['decay_index'] = ((end_time - df_qc['score_recorded_at']).dt.total_seconds()) / (3600 * 24) \n",
    "    df_qc.loc[df_qc['decay_index'] < 0, 'decay_index'] = 0 # qc时间有时会在end_time之后造成负值\n",
    "    df_qc['decay_index'] = df_qc['decay_index'] + 2 # log计算，防止0值+1;取倒数+1，防止无穷情况\n",
    "    df_qc['decay_index'] = df_qc['decay_index'].apply(lambda x: math.log(x, 10))\n",
    "    df_qc['decay_index'] = 1 / df_qc['decay_index']\n",
    "    df_qc['log_decay_score'] = df_qc['score'] * df_qc['decay_index']\n",
    "    df_teacher_log_score = df_qc.groupby(['awj_teacher_id'], \n",
    "                        as_index=False).agg({'log_decay_score': np.sum, 'decay_index': np.sum})\n",
    "    df_teacher_log_score['log_decay_score_mean'] = df_teacher_log_score['log_decay_score'] / df_teacher_log_score['decay_index']\n",
    "    df_teacher_log_score = df_teacher_log_score[['awj_teacher_id', 'log_decay_score_mean']]\n",
    "    # score\n",
    "    df_teacher_score = df_qc.groupby(['awj_teacher_id'], \n",
    "                as_index=False)['score'].agg(['max', 'min', 'count', np.std]) \n",
    "    # std missing\n",
    "    df_teacher_score.loc[df_teacher_score['std'].isnull(), 'std'] = df_teacher_score['std'].mean()\n",
    "    df_teacher_score.rename(columns={'max': 'teacher_score_max', 'min': 'teacher_score_min', \n",
    "                        'count': 'teacher_qc_count', 'std': 'teacher_score_std'}, inplace=True)\n",
    "    df_teacher_score.reset_index(inplace=True)\n",
    "    # merge\n",
    "    df_qc_res = pd.merge(df_teacher_score, df_teacher_log_score, on='awj_teacher_id', how='left')\n",
    "    return df_qc_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1006,
   "metadata": {},
   "outputs": [],
   "source": [
    "def teacher_behavior(start_time, end_time, df_teacher_behavior, \n",
    "                         class_type_name_special, hq_name_special):\n",
    "    # 筛选条件\n",
    "    df_teacher_behavior = df_teacher_behavior.loc[\n",
    "                    (~df_teacher_behavior['上课类型'].isin(class_type_name_special)) & \n",
    "                    (~df_teacher_behavior['机构'].isin(hq_name_special)) & \n",
    "                    (df_teacher_behavior['start_time'] >= start_time) & \n",
    "                    (df_teacher_behavior['end_time'] <= end_time) & \n",
    "                    (~df_teacher_behavior['teacher_status_for_lesson'].isin(['system_failure']))]\n",
    "    # 预处理\n",
    "    df_teacher_behavior['lesson_count'] = ((df_teacher_behavior['end_time'] - \n",
    "                        df_teacher_behavior['start_time']).dt.total_seconds()) / 3600 * 2\n",
    "    df_teacher_behavior.loc[df_teacher_behavior['teacher_status_for_lesson'] == 'no_show', \n",
    "                            'ask_for_leave_advanced_minutes'] = 0\n",
    "    df_teacher_behavior['ask_for_leave_advanced_days'] = df_teacher_behavior['ask_for_leave_advanced_minutes'] / (60 * 24)\n",
    "    # 天数衰减\n",
    "    df_teacher_behavior['decay_index'] = ((end_time - \n",
    "            df_teacher_behavior['start_time']).dt.total_seconds()) / (3600 * 24) \n",
    "    df_teacher_behavior.loc[df_teacher_behavior['decay_index'] < 0, 'decay_index'] = 0\n",
    "    # log计算，防止0值+1;取倒数+1，防止无穷情况\n",
    "    df_teacher_behavior['decay_index'] = df_teacher_behavior['decay_index'] + 2\n",
    "    df_teacher_behavior['decay_index'] = df_teacher_behavior['decay_index'].apply(lambda x: math.log(x, 10))\n",
    "    df_teacher_behavior['decay_index'] = 1 / df_teacher_behavior['decay_index']\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # count lesson types\n",
    "    df_teacher_behavior_res = df_teacher_behavior[['awj_teacher_id']]\n",
    "    df_teacher_behavior_res.drop_duplicates(keep='first', inplace=True)\n",
    "    types = ['normal_lesson', 'late', 'no_show', 'abnormal_lesson', 'ask_for_leave']\n",
    "    for itm in types:\n",
    "        df_count = df_teacher_behavior.loc[\n",
    "            df_teacher_behavior['teacher_status_for_lesson'].isin([itm])]\n",
    "        df_count['log_lesson_count'] = df_count['lesson_count'] * df_count['decay_index']\n",
    "        df_count = df_count.groupby(['awj_teacher_id'], as_index=False)['log_lesson_count'].sum()\n",
    "        df_count.reset_index()\n",
    "        if (itm.find('ask_for_leave') > -1) | (itm.find('lesson') > -1):\n",
    "            df_count.rename(columns={'log_lesson_count': itm + '_log_count'}, inplace=True)\n",
    "        else:\n",
    "            df_count.rename(columns={'log_lesson_count': itm + '_lesson_log_count'}, inplace=True)\n",
    "        df_teacher_behavior_res = pd.merge(df_teacher_behavior_res, df_count, \n",
    "                                          on='awj_teacher_id', how='left')\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    # ask for leave advanced minutes\n",
    "    df_advanced_days = df_teacher_behavior.loc[\n",
    "        df_teacher_behavior['teacher_status_for_lesson'].isin(['ask_for_leave', 'no_show'])]  \n",
    "    df_advanced_days['ask_for_leave_advanced_log_days'] = df_advanced_days['decay_index'] * df_advanced_days['ask_for_leave_advanced_days']\n",
    "    # 求均值\n",
    "    df_advanced_days_mean = df_advanced_days.groupby(['awj_teacher_id'], as_index=False).agg(\n",
    "        {'ask_for_leave_advanced_log_days': np.sum, 'decay_index': np.sum})\n",
    "    df_advanced_days_mean.reset_index(inplace=True)\n",
    "    df_advanced_days_mean['advanced_days_log_mean'] = df_advanced_days_mean['ask_for_leave_advanced_log_days'] / df_advanced_days_mean['decay_index'] \n",
    "    df_advanced_days_mean = df_advanced_days_mean[['awj_teacher_id', 'advanced_days_log_mean']]\n",
    "    # 求最大最小值及方差\n",
    "    df_advanced_days_others = df_advanced_days.groupby(['awj_teacher_id'], \n",
    "            as_index=False)['ask_for_leave_advanced_days'].agg(['min', 'max', 'std'])\n",
    "    df_advanced_days_others.reset_index(inplace=True)\n",
    "    df_advanced_days_others.loc[df_advanced_days_others['std'].isnull(), \n",
    "                                'std'] = df_advanced_days_others['std'].mean()\n",
    "    df_advanced_days_others.rename(columns={'min': 'advanced_days_min', \n",
    "                    'max': 'advanced_days_max', 'std': 'advanced_days_std'}, inplace=True)\n",
    "    df_advanced_days = pd.merge(df_advanced_days_mean, df_advanced_days_others, \n",
    "                               on='awj_teacher_id', how='left')\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    df_teacher_behavior_res = pd.merge(df_teacher_behavior_res, df_advanced_days, \n",
    "                                                       on='awj_teacher_id', how='left')\n",
    "    # fill 0\n",
    "    columns = ['normal_lesson_log_count', 'late_lesson_log_count', 'no_show_lesson_log_count', \n",
    "               'abnormal_lesson_log_count', 'ask_for_leave_log_count', 'advanced_days_log_mean', \n",
    "               'advanced_days_min', 'advanced_days_max', 'advanced_days_std']\n",
    "    for itm in columns:\n",
    "        df_teacher_behavior_res[itm].fillna(value=0, inplace=True)\n",
    "    return df_teacher_behavior_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1007,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stu_comment(start_time, end_time, df_stu_comment, class_type_name_special, hq_name_special):\n",
    "    # 筛选条件：时间筛选条件由于筛选后数量过少，所以采用全量数据\n",
    "    df_stu_comment = df_stu_comment.loc[~df_stu_comment['机构'].isin(hq_name_special)]\n",
    "    # 天数衰减\n",
    "    df_stu_comment['decay_index'] = ((end_time - \n",
    "            df_stu_comment['评价时间']).dt.total_seconds()) / (3600 * 24) \n",
    "    df_stu_comment.loc[df_stu_comment['decay_index'] < 0, 'decay_index'] = 0\n",
    "    # log计算，防止0值+1;取倒数+1，防止无穷情况\n",
    "    df_stu_comment['decay_index'] = df_stu_comment['decay_index'] + 2\n",
    "    df_stu_comment['decay_index'] = df_stu_comment['decay_index'].apply(lambda x: math.log(x, 10))\n",
    "    df_stu_comment['decay_index'] = 1 / df_stu_comment['decay_index']  \n",
    "    # 正面标签统计:有时一次课有多个好评标签，导致有些老师上课次数很少，但好评标签总量超过次数本身，不公平\n",
    "    # 所以此处每堂课不管有几个好评标签，都算做一个好评统计\n",
    "    df_good_label = df_stu_comment.loc[(df_stu_comment['学生评价星级'].isin(['5-star', '4-star'])) & \n",
    "            (df_stu_comment['标签内容'].isin(['老师有耐心', '课堂氛围好', '课程生动有趣', '互动丰富']))]\n",
    "    df_good_label = df_good_label.groupby(['评价id'], as_index=False).first()\n",
    "    df_good_label['标签内容'] = 1\n",
    "    df_good_label['标签内容_processed'] = df_good_label['标签内容'] * df_good_label['decay_index']\n",
    "    df_good_label = df_good_label.groupby(['awj_teacher_id'], \n",
    "                            as_index=False)['标签内容_processed'].sum()\n",
    "    df_good_label.rename(columns={'标签内容_processed': 'stu_comment_log_good_behavior'}, inplace=True)\n",
    "    # 负面标签统计：主观原因。客观原因---产品说环境原因可能是因为是视频供应商平台或学生自己网络问题，所以不应该计入\n",
    "    # 去除4星及5星的数据，理论上，四星五星无负面评价，有的都是系统bug导致\n",
    "    df_bad_label = df_stu_comment.loc[(~df_stu_comment['学生评价星级'].isin(['5-star', '4-star'])) & \n",
    "                    (df_stu_comment['标签内容'].isin(['老师语速过快', '互动较少', \n",
    "                    '课堂氛围差', '未及时纠正错误', '老师缺乏耐心']))]\n",
    "    df_bad_label = df_bad_label.groupby(['评价id'], as_index=False).first()\n",
    "    df_bad_label['标签内容'] = 1\n",
    "    df_bad_label['标签内容_processed'] = df_bad_label['标签内容'] * df_bad_label['decay_index']\n",
    "    df_bad_label = df_bad_label.groupby(['awj_teacher_id'], \n",
    "                                as_index=False)['标签内容_processed'].sum()\n",
    "    df_bad_label.rename(columns={'标签内容_processed': 'stu_comment_log_bad_behavior'}, inplace=True)\n",
    "    # merge\n",
    "    df_stu_comment_res = pd.merge(df_good_label, df_bad_label, on='awj_teacher_id', how='outer')\n",
    "    df_stu_comment_res['stu_comment_log_bad_behavior'].fillna(value=0, inplace=True)\n",
    "    df_stu_comment_res['stu_comment_log_good_behavior'].fillna(value=0, inplace=True)\n",
    "    return df_stu_comment_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1008,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start_time: 2018-01-30 23:59:59.964000 \n",
      " end_time: 2018-04-30 23:59:59.964000 \n",
      "\n",
      "df_teacher_monitoring key check_duplicate no(awj_teacher_id, awjcls_lesson_id): 0 \n",
      "\n",
      "df_qc_before drop duplicates: (29311, 17)\n",
      "df_qc_drop duplicates: (24184, 17)\n",
      "df_qc key check_duplicate no(awj_teacher_id, awjcls_lesson_id): 0 \n",
      "\n",
      "df_teacher_behavior shape: (241621, 13)\n",
      "df_teacher_behavior shape(teacher_id+lesson_id as key:) (241469, 13)\n",
      "df_teacher_behavior shape(no abnormal_type=4, 5) (241467, 13)\n",
      "df_teacher_behavior key check_duplicate no(awj_teacher_id, awj_lesson_id): 0 \n",
      "\n",
      "df_teacher_info key check duplicate no(awj_teacher_id): 0 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/pandas/core/indexing.py:517: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/ipykernel_launcher.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/ipykernel_launcher.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/ipykernel_launcher.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/ipykernel_launcher.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/ipykernel_launcher.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " no_show_lesson_log_percent :\n",
      "0.1 : 0.0017861690310692672\n",
      "0.15 : 0.002330144202808163\n",
      "0.2 : 0.0029021563036939345\n",
      "0.25 : 0.003482588679703572\n",
      "0.3 : 0.004098390217401592\n",
      "0.33 : 0.004665703610870716\n",
      "0.5 : 0.01054202982440932\n",
      "0.55 : 0.012818233492788964\n",
      "0.6 : 0.012832725816617648\n",
      "0.66 : 0.014951704763786688\n",
      "0.7 : 0.01846137967319565\n",
      "0.75 : 0.02972795413302779\n",
      "0.77 : 0.03313220669342654\n",
      "0.8 : 0.03820796181046023\n",
      "0.83 : 0.045262864422940044\n",
      "0.85 : 0.05877166648082807\n",
      "0.9 : 0.09928910002012299\n",
      "0.92 : 0.12949367713011428\n",
      "0.95 : 0.2660843838119369\n",
      "1 : 25.901074963742026\n",
      "\n",
      " late_lesson_log_percent :\n",
      "0.1 : 0.0018666196682732292\n",
      "0.15 : 0.002294058535537647\n",
      "0.2 : 0.002680781955185766\n",
      "0.25 : 0.0031247849804458077\n",
      "0.3 : 0.0036492894179306415\n",
      "0.33 : 0.004114415749656181\n",
      "0.5 : 0.010127500480385179\n",
      "0.55 : 0.012926512259553491\n",
      "0.6 : 0.016083105469158032\n",
      "0.66 : 0.0243806899156339\n",
      "0.7 : 0.027049405497154167\n",
      "0.75 : 0.027432159700350782\n",
      "0.77 : 0.033138320012811084\n",
      "0.8 : 0.038847984811040494\n",
      "0.83 : 0.04528571788436045\n",
      "0.85 : 0.057911987917591105\n",
      "0.9 : 0.10609460399596377\n",
      "0.92 : 0.14105921153980014\n",
      "0.95 : 0.217304992849163\n",
      "1 : 1.3932692532782813\n",
      "\n",
      " abnormal_lesson_log_percent :\n",
      "0.1 : 0.0017264601796629026\n",
      "0.15 : 0.0020614434510611845\n",
      "0.2 : 0.0025430605232131883\n",
      "0.25 : 0.0029278790532385485\n",
      "0.3 : 0.003443197301057362\n",
      "0.33 : 0.003906138684766238\n",
      "0.5 : 0.0063989186023248\n",
      "0.55 : 0.006733663694365081\n",
      "0.6 : 0.008081400435609702\n",
      "0.66 : 0.01063342083735283\n",
      "0.7 : 0.01285111243702642\n",
      "0.75 : 0.015404743875404291\n",
      "0.77 : 0.01796050284557328\n",
      "0.8 : 0.023394279264119754\n",
      "0.83 : 0.031010940996210448\n",
      "0.85 : 0.03557910475847159\n",
      "0.9 : 0.05239790294465545\n",
      "0.92 : 0.07113775208575125\n",
      "0.95 : 0.11307085607681683\n",
      "1 : 0.5899993170440806\n",
      "\n",
      " ask_for_leave_log_percent :\n",
      "0.1 : 0.001967583589062985\n",
      "0.15 : 0.003074601774001384\n",
      "0.2 : 0.004661843242748692\n",
      "0.25 : 0.008226927051879832\n",
      "0.3 : 0.011706992522366455\n",
      "0.33 : 0.01630320462316386\n",
      "0.5 : 0.05164494329815373\n",
      "0.55 : 0.06760917312633347\n",
      "0.6 : 0.09884054431223749\n",
      "0.66 : 0.11219074480957186\n",
      "0.7 : 0.1158620209796389\n",
      "0.75 : 0.18708960265978175\n",
      "0.77 : 0.22090931919856263\n",
      "0.8 : 0.29131339182192434\n",
      "0.83 : 0.3942704381223182\n",
      "0.85 : 0.4979874072965468\n",
      "0.9 : 1.0985309385733015\n",
      "0.92 : 1.7078874570443512\n",
      "0.95 : 3.195649943805474\n",
      "1 : 111.44349722934025\n",
      "\n",
      " abnormal_all_log_percent :\n",
      "0.1 : 0.0\n",
      "0.15 : 0.0035355711840005214\n",
      "0.2 : 0.0075440678220861125\n",
      "0.25 : 0.01578659779851897\n",
      "0.3 : 0.023802142391882487\n",
      "0.33 : 0.02992206252955872\n",
      "0.5 : 0.07599503301650623\n",
      "0.55 : 0.0977475231172966\n",
      "0.6 : 0.12741363203609707\n",
      "0.66 : 0.17756690877697479\n",
      "0.7 : 0.17756690877697479\n",
      "0.75 : 0.19620333027771444\n",
      "0.77 : 0.2230220729463343\n",
      "0.8 : 0.2712970630752666\n",
      "0.83 : 0.3465032073688308\n",
      "0.85 : 0.4303255453494709\n",
      "0.9 : 0.5814311833911318\n",
      "0.92 : 0.6427611874159216\n",
      "0.95 : 0.7749519095744499\n",
      "1 : 0.9910910609207563\n",
      "\n",
      " log_ask_for_leave/log_normal_lesson :\n",
      "0.1 : 0.0\n",
      "0.15 : 0.0\n",
      "0.2 : 0.0\n",
      "0.25 : 0.0\n",
      "0.3 : 0.0\n",
      "0.33 : 0.0\n",
      "0.5 : 0.037098225680022044\n",
      "0.55 : 0.055667129560402984\n",
      "0.6 : 0.08198550009649154\n",
      "0.66 : 0.1257380659722838\n",
      "0.7 : 0.18831634823164595\n",
      "0.75 : 0.31943823152705764\n",
      "0.77 : 0.3990137399128372\n",
      "0.8 : 0.6210259681269742\n",
      "0.83 : 1.0094099345502259\n",
      "0.85 : 1.0094099345502259\n",
      "0.9 : 1.088080988179521\n",
      "0.92 : 1.6762033184222433\n",
      "0.95 : 3.137322713213162\n",
      "1 : 111.24681088344423\n",
      "\n",
      " advanced_days_log_mean :\n",
      "0.1 : 2.304220497201397\n",
      "0.15 : 6.773031326497039\n",
      "0.2 : 13.533951683798795\n",
      "0.25 : 22.32416014648762\n",
      "0.3 : 22.32416014648762\n",
      "0.33 : 24.568702454132893\n",
      "0.5 : 34.33399313668666\n",
      "0.55 : 34.33399313668666\n",
      "0.6 : 34.33399313668666\n",
      "0.66 : 34.33399313668666\n",
      "0.7 : 34.33399313668666\n",
      "0.75 : 34.33399313668666\n",
      "0.77 : 35.49274550009275\n",
      "0.8 : 40.897222222222226\n",
      "0.83 : 49.079538865814754\n",
      "0.85 : 52.383477106083696\n",
      "0.9 : 61.26543856438198\n",
      "0.92 : 70.3886981886576\n",
      "0.95 : 85.08173221947487\n",
      "1 : 181.72708333333333\n",
      "\n",
      " advanced_days_max :\n",
      "0.1 : 5.644444444444444\n",
      "0.15 : 14.725868055555555\n",
      "0.2 : 31.869444444444444\n",
      "0.25 : 37.84632958456243\n",
      "0.3 : 38.23670645894788\n",
      "0.33 : 42.35267361111112\n",
      "0.5 : 58.20669676613084\n",
      "0.55 : 58.20669676613084\n",
      "0.6 : 58.20669676613084\n",
      "0.66 : 58.20669676613084\n",
      "0.7 : 58.20669676613084\n",
      "0.75 : 58.718340858199376\n",
      "0.77 : 65.61788194444445\n",
      "0.8 : 71.52361111111111\n",
      "0.83 : 79.90440972222223\n",
      "0.85 : 85.71875000000001\n",
      "0.9 : 106.28680555555556\n",
      "0.92 : 128.16625000000002\n",
      "0.95 : 157.55902777777777\n",
      "1 : 221.8513888888889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/ipykernel_launcher.py:319: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    path = path = '/Users/roger.zhou/Downloads/星级老师/'\n",
    "    end_time = pd.to_datetime(datetime.datetime.now().date()) + MonthEnd(n=-1) + DateOffset(hours=23.99999)\n",
    "    start_time = end_time - DateOffset(months=3)\n",
    "    class_type_name_special = ['Demo', '补课(非爱乐奇直属老师)', '托福班（30刀）', 'TOFEL', \n",
    "                              'VIP Writing/TOFEL（35刀）', 'Elite Pilot', 'Feeback Session', \n",
    "                              'New Teacher Test Class', '补课(爱乐奇直属老师)', 'Test Class', \n",
    "                              'Academic Meeting (Long)', 'Cur Experience Session-S', \n",
    "                              'Training-receiving', 'Cur Experience Session-L', \n",
    "                              'VIP Writing/TOFEL', 'Orientation Class', 'Academic Meeting', \n",
    "                              'Experience-receiving']\n",
    "    hq_name_special = ['test']\n",
    "    print('start_time:', start_time, '\\n', 'end_time:', end_time, '\\n')\n",
    "    \n",
    "    ##### 老师监控表 #####\n",
    "    df_teacher_monitoring = pd.read_csv(path + 'awj_teacher_monitoring.csv', encoding='utf-8', sep=',')\n",
    "    # dtypes\n",
    "    df_teacher_monitoring['awj_teacher_id'] = df_teacher_monitoring['awj_teacher_id'].astype('int')\n",
    "    df_teacher_monitoring['created_at'] = pd.to_datetime(df_teacher_monitoring['created_at'])\n",
    "    # drop duplicates\n",
    "    df_teacher_monitoring.drop_duplicates(\n",
    "                        subset=list(df_teacher_monitoring.columns), keep='first', inplace=True)\n",
    "    # sort\n",
    "    df_teacher_monitoring = df_teacher_monitoring.sort_values(\n",
    "                                by=['awj_teacher_id', 'created_at'], ascending=[1, 1])\n",
    "    # 该表只取abnormal_type为4，5的行，分别表示zoom崩溃和课件崩溃，非老师原因\n",
    "    df_teacher_monitoring = df_teacher_monitoring.loc[\n",
    "                    df_teacher_monitoring['abnormal_type'].isin([4, 5])]\n",
    "    df_teacher_monitoring = df_teacher_monitoring.groupby(\n",
    "                ['awj_teacher_id', 'awjcls_lesson_id', 'abnormal_type'], as_index=False).last()\n",
    "    # 唯一主键awj_teacher_id+awjcls_lesson_id check\n",
    "    cache = df_teacher_monitoring.groupby(['awj_teacher_id', 'awjcls_lesson_id'], \n",
    "                                      as_index=False)['abnormal_type'].count()\n",
    "    print('df_teacher_monitoring key check_duplicate no(awj_teacher_id, awjcls_lesson_id):', \n",
    "          cache.loc[cache['abnormal_type'] > 1].shape[0], '\\n')\n",
    "    \n",
    "    ##### 老师QC明细表 #####\n",
    "    df_qc = pd.read_csv(path + '老师qc明细.csv', encoding='utf-8', sep=',')\n",
    "    # dtypes\n",
    "    df_qc['awj_teacher_id'] = df_qc['awj_teacher_id'].astype('int')\n",
    "    df_qc['score_recorded_at'] = pd.to_datetime(df_qc['score_recorded_at'])\n",
    "    df_qc['assigned_at'] = pd.to_datetime(df_qc['assigned_at'])\n",
    "    df_qc['start_time'] = pd.to_datetime(df_qc['start_time'])\n",
    "    df_qc['end_time'] = pd.to_datetime(df_qc['end_time'])\n",
    "    print('df_qc_before drop duplicates:', df_qc.shape)\n",
    "    # drop duplicates-老师同一堂课有时会有多次qc，check后发现分数都一样，所以去重时按照一下字段去重即可\n",
    "    columns = ['awj_teacher_id', 'awjcls_lesson_id', 'score']\n",
    "    df_qc.drop_duplicates(subset=columns, keep='first', inplace=True)\n",
    "    print('df_qc_drop duplicates:', df_qc.shape)\n",
    "    # sort\n",
    "    df_qc = df_qc.sort_values(by=['awj_teacher_id', 'start_time'], ascending=[1, 1])\n",
    "    # 唯一主键awj_teacher_id+awjcls_lesson_id check\n",
    "    cache = df_qc.groupby(['awj_teacher_id', 'awjcls_lesson_id'], \n",
    "                                      as_index=False)['teacher_name'].count()\n",
    "    print('df_qc key check_duplicate no(awj_teacher_id, awjcls_lesson_id):', \n",
    "          cache.loc[cache['teacher_name'] > 1].shape[0], '\\n')\n",
    "    \n",
    "    ##### 老师行为表 #####\n",
    "    df_teacher_behavior = pd.read_csv(path + '老师行为信息明细.csv', sep=',', encoding='utf-8')\n",
    "    # dtypes\n",
    "    df_teacher_behavior['awj_teacher_id'] = df_teacher_behavior['awj_teacher_id'].astype('int')\n",
    "    df_teacher_behavior['start_time'] = pd.to_datetime(df_teacher_behavior['start_time'])\n",
    "    df_teacher_behavior['end_time'] = pd.to_datetime(df_teacher_behavior['end_time'])\n",
    "    df_teacher_behavior['actual_start_time'] = pd.to_datetime(df_teacher_behavior['actual_start_time'])\n",
    "    df_teacher_behavior['actual_end_time'] = pd.to_datetime(df_teacher_behavior['actual_end_time'])\n",
    "    df_teacher_behavior.drop_duplicates(subset=list(df_teacher_behavior.columns), inplace=True)\n",
    "    # sort\n",
    "    df_teacher_behavior = df_teacher_behavior.sort_values(by=[\n",
    "            'awj_teacher_id', 'awj_lesson_id', 'start_time', '积分变化'], ascending=[1, 1, 1, 1])\n",
    "    print('df_teacher_behavior shape:', df_teacher_behavior.shape)\n",
    "    # 老师id加lesson_id应该唯一，但有时有重复情况，因为有些老师先请了假，后来又来上课了，所以请假应该去除\n",
    "    df_teacher_behavior = df_teacher_behavior.groupby(\n",
    "                ['awj_teacher_id', 'awj_lesson_id'], as_index=False).last()\n",
    "    print('df_teacher_behavior shape(teacher_id+lesson_id as key:)', df_teacher_behavior.shape)\n",
    "    # 与monitoring表对比，去除老师abnormal_lesson细分为4，5状态下的课程记录\n",
    "    df_teacher_behavior = pd.merge(df_teacher_behavior, \n",
    "                    df_teacher_monitoring[['awj_teacher_id', 'awjcls_lesson_id', 'abnormal_type']], \n",
    "                    left_on=['awj_teacher_id', 'awj_lesson_id'], \n",
    "                    right_on=['awj_teacher_id', 'awjcls_lesson_id'], how='left')\n",
    "    index = df_teacher_behavior.loc[\n",
    "                    (df_teacher_behavior['teacher_status_for_lesson'] == 'abnormal_lesson') & \n",
    "                    (df_teacher_behavior['abnormal_type'].isin([4, 5]))].index\n",
    "    df_teacher_behavior = df_teacher_behavior.loc[~df_teacher_behavior.index.isin(list(index))]\n",
    "    df_teacher_behavior.drop(['awjcls_lesson_id', 'abnormal_type'], axis=1, inplace=True)\n",
    "    print('df_teacher_behavior shape(no abnormal_type=4, 5)', df_teacher_behavior.shape)\n",
    "    # 唯一主键awj_teacher_id+awjcls_lesson_id check\n",
    "    cache = df_teacher_behavior.groupby(['awj_teacher_id', 'awj_lesson_id'], \n",
    "                                      as_index=False)['start_time'].count()\n",
    "    print('df_teacher_behavior key check_duplicate no(awj_teacher_id, awj_lesson_id):', \n",
    "          cache.loc[cache['start_time'] > 1].shape[0], '\\n')\n",
    "    \n",
    "    ##### 老师信息表 #####\n",
    "    df_teacher_info = pd.read_csv(path + '老师基本信息.csv', sep=',', encoding='utf-8')\n",
    "    # dtypes\n",
    "    df_teacher_info['awj_teacher_id'] = df_teacher_info['awj_teacher_id'].astype(int)\n",
    "    df_teacher_info['创建时间'] = pd.to_datetime(df_teacher_info['创建时间'])\n",
    "    df_teacher_info['首次上架时间'] = pd.to_datetime(df_teacher_info['首次上架时间'])\n",
    "    df_teacher_info['首课时间'] = pd.to_datetime(df_teacher_info['首课时间'])\n",
    "    df_teacher_info.drop_duplicates(subset=list(df_teacher_info.columns), \n",
    "                                                    keep='first', inplace=True)\n",
    "    # 根据业务要求去除只取某些type类型老师，其他去除\n",
    "    df_teacher_info = df_teacher_info.loc[df_teacher_info['teacher_type'].isin([\n",
    "                'booking&arrangement', 'arrangement_only', 'booking_only'])]\n",
    "    # sort\n",
    "    df_teacher_info = df_teacher_info.sort_values(by=['awj_teacher_id'], ascending=[1])\n",
    "    df_teacher_info = df_teacher_info[['awj_teacher_id', 'state', '创建时间', \n",
    "                                                           '首次上架时间', '首课时间']]\n",
    "    print('df_teacher_info key check duplicate no(awj_teacher_id):', \n",
    "          df_teacher_info.shape[0] - df_teacher_info['awj_teacher_id'].nunique(), '\\n')\n",
    "    \n",
    "    ##### 学生评价明细表(去重在函数内完成) #####\n",
    "    df_stu_comment = pd.read_csv(path + '学生评价明细.csv', sep=',', encoding='utf-8')\n",
    "    # dtypes\n",
    "    df_stu_comment['awj_teacher_id'] = df_stu_comment['awj_teacher_id'].astype(int)\n",
    "    df_stu_comment['评价时间'] = pd.to_datetime(df_stu_comment['评价时间'])\n",
    "    df_stu_comment.drop_duplicates(subset=list(df_stu_comment.columns), keep='first', inplace=True)\n",
    "    # sort\n",
    "    df_stu_comment = df_stu_comment.sort_values(by=[\n",
    "                    'awj_teacher_id', '评价时间'], ascending=[1, 1])  \n",
    "    \n",
    "    # 函数调用\n",
    "    df_qc_res = teacher_qc_score(start_time, end_time, df_qc, \n",
    "                                 class_type_name_special, hq_name_special)\n",
    "    df_teacher_behavior_res = teacher_behavior(start_time, \n",
    "                        end_time, df_teacher_behavior, class_type_name_special, hq_name_special)\n",
    "    df_stu_comment_res = stu_comment(start_time, end_time, df_stu_comment, \n",
    "                                     class_type_name_special, hq_name_special)\n",
    "    # 宽表\n",
    "    df_wide = pd.merge(df_teacher_info, df_teacher_behavior_res, on='awj_teacher_id', how='left')\n",
    "    df_wide = pd.merge(df_wide, df_qc_res, on='awj_teacher_id', how='left')\n",
    "    df_wide = pd.merge(df_wide, df_stu_comment_res, on='awj_teacher_id', how='left')\n",
    "    # 学生评价---采用全量数据，需用到全量老师上课数值\n",
    "    df_lesson_count_all = teacher_behavior(end_time - DateOffset(months=360), end_time, \n",
    "                            df_teacher_behavior, class_type_name_special, hq_name_special)\n",
    "    df_lesson_count_all = df_lesson_count_all[['awj_teacher_id', 'normal_lesson_log_count', \n",
    "                                        'late_lesson_log_count', 'no_show_lesson_log_count', \n",
    "                                        'ask_for_leave_log_count', 'abnormal_lesson_log_count']]\n",
    "    df_lesson_count_all.rename(columns={'normal_lesson_log_count': 'normal_lesson_log_count_all', \n",
    "                                    'late_lesson_log_count': 'late_lesson_log_count_all', \n",
    "                                    'no_show_lesson_log_count': 'no_show_lesson_log_count_all', \n",
    "                                    'ask_for_leave_log_count': 'ask_for_leave_log_count_all', \n",
    "                                    'abnormal_lesson_log_count': 'abnormal_lesson_log_count_all'}, \n",
    "                                    inplace=True)\n",
    "    df_wide = pd.merge(df_wide, df_lesson_count_all, on='awj_teacher_id', how='left')\n",
    "    # 衍生新字段\n",
    "    df_wide['log_ask_for_leave/log_normal_lesson'] = df_wide['ask_for_leave_log_count'] / df_wide['normal_lesson_log_count']\n",
    "    df_wide['abnormal_all_log_count'] = (df_wide['no_show_lesson_log_count'] + \n",
    "                                      df_wide['late_lesson_log_count'] + \n",
    "                                      df_wide['abnormal_lesson_log_count'] + \n",
    "                                      df_wide['ask_for_leave_log_count'])\n",
    "    df_wide['abnormal_all_log_percent'] = (df_wide['abnormal_all_log_count']) / (\n",
    "                                      df_wide['normal_lesson_log_count'] + \n",
    "                                      df_wide['abnormal_all_log_count'])\n",
    "    df_wide['lesson_time_range'] = ((end_time - df_wide['首课时间']).dt.total_seconds()) / (3600 * 24) \n",
    "    df_wide.loc[df_wide['lesson_time_range'] == 0, 'lesson_time_range'] = ((end_time - df_wide['创建时间']).dt.total_seconds()) / (3600 * 24)  \n",
    "    # 判断是否是新老师\n",
    "    df_wide['old_new_teacher'] = 'old'\n",
    "    df_wide.loc[(df_wide['首课时间'].isnull()) & \n",
    "                (df_wide['state'].isin(['oboard', 'active'])), 'old_new_teacher'] = 'new'\n",
    "    # 缺失值填补\n",
    "    # 无用字段去除\n",
    "    df_wide.drop(['创建时间', '首次上架时间', '首课时间', 'state'], axis=1, inplace=True)\n",
    "    columns = list(df_wide.columns)\n",
    "    columns.pop(columns.index('awj_teacher_id'))\n",
    "    columns.pop(columns.index('old_new_teacher'))\n",
    "    # new teacher: mean\n",
    "    for itm in columns:\n",
    "        df_wide.loc[df_wide['old_new_teacher'] == 'new', itm] = df_wide.loc[\n",
    "            (df_wide['normal_lesson_log_count'] > 0), itm].mean()\n",
    "    # old teacher:0\n",
    "    df_wide.fillna(value=0, inplace=True)\n",
    "    new_teacher = df_wide.loc[df_wide['old_new_teacher'] == 'new', 'awj_teacher_id']\n",
    "    # 有些老师没有请过假，advanced_days字段为0，填为均值\n",
    "    df_wide.loc[(df_wide['ask_for_leave_log_count'] == 0) & (df_wide['normal_lesson_log_count'] > 0), \n",
    "        'advanced_days_max'] = df_wide.loc[(df_wide['advanced_days_max'] != 0) & \n",
    "                        df_wide['normal_lesson_log_count'] > 0, 'advanced_days_max'].mean()\n",
    "    df_wide.loc[(df_wide['ask_for_leave_log_count'] == 0) & (df_wide['normal_lesson_log_count'] > 0), \n",
    "        'advanced_days_log_mean'] = df_wide.loc[(df_wide['advanced_days_log_mean'] != 0) & \n",
    "                        df_wide['normal_lesson_log_count'] > 0, 'advanced_days_log_mean'].mean()\n",
    "    # 平滑\n",
    "    smooth = ['late_lesson_log_count', 'no_show_lesson_log_count', 'abnormal_lesson_log_count', \n",
    "              'ask_for_leave_log_count', 'stu_comment_log_bad_behavior']\n",
    "    for itm in smooth:\n",
    "        df_wide[itm] = df_wide[itm] + math.log(2, 10)\n",
    "    # 字段处理\n",
    "    # 比例计算\n",
    "    df_wide['late_lesson_log_percent'] = df_wide['late_lesson_log_count'] / df_wide['normal_lesson_log_count']\n",
    "    df_wide['no_show_lesson_log_percent'] = df_wide['no_show_lesson_log_count'] / df_wide['normal_lesson_log_count']\n",
    "    df_wide['abnormal_lesson_log_percent'] = df_wide['abnormal_lesson_log_count'] / df_wide['normal_lesson_log_count']\n",
    "    df_wide['ask_for_leave_log_percent'] = df_wide['ask_for_leave_log_count'] / df_wide['normal_lesson_log_count']\n",
    "    # 查看上课异常行为的分位数\n",
    "    columns = ['no_show_lesson_log_percent', 'late_lesson_log_percent', \n",
    "               'abnormal_lesson_log_percent', 'ask_for_leave_log_percent', \n",
    "               'abnormal_all_log_percent', 'log_ask_for_leave/log_normal_lesson', \n",
    "               'advanced_days_log_mean', 'advanced_days_max']\n",
    "    quantiles = [0.1, 0.15, 0.2, 0.25, 0.3, 0.33, 0.5, 0.55, 0.6, 0.66, 0.7, 0.75, \n",
    "                 0.77, 0.8, 0.83, 0.85, 0.9, 0.92, 0.95, 1]\n",
    "    for i in range(len(columns)):\n",
    "        print('\\n', columns[i], ':')\n",
    "        for itm in quantiles:\n",
    "            print(str(itm), ':', df_wide.loc[df_wide['normal_lesson_log_count'] > 0, \n",
    "                                                        columns[i]].quantile(itm))\n",
    "    # 老师异常行为有一项出现较大异常值时或整体较差，normal_lesson_log_count降为相应较低数值，整体表现变差\n",
    "    counts = ['ask_for_leave_log_count', 'late_lesson_log_count', \n",
    "               'no_show_lesson_log_count', 'abnormal_lesson_log_count', \n",
    "               'abnormal_all_log_count']\n",
    "    columns = ['ask_for_leave_log_percent', 'late_lesson_log_percent', \n",
    "               'no_show_lesson_log_percent', 'abnormal_lesson_log_percent', \n",
    "               'abnormal_all_log_percent']\n",
    "    cache_columns = ['normal_lesson_log_count_processed_ask_for_leave_cahce1', \n",
    "                     'normal_lesson_log_count_processed_late_lesson_cache2', \n",
    "                     'normal_lesson_log_count_processed_no_show_cache3', \n",
    "                     'normal_lesson_log_count_processed_abnormal_lesson_cache4', \n",
    "                     'normal_lesson_log_count_processed_abnormal_all_cahce5'\n",
    "                    ]\n",
    "    for itm in cache_columns:\n",
    "        df_wide[itm] = df_wide['normal_lesson_log_count']\n",
    "    df_wide['normal_lesson_log_count_processed'] = df_wide['normal_lesson_log_count']\n",
    "    # 分位数\n",
    "    quantiles = [[0.6, 0.7, 0.75, 0.8, 1], [0.8, 0.9, 0.92, 0.95, 1], \n",
    "                [0.5, 0.6, 0.66, 0.75, 0.8, 0.85, 0.9, 1], [0.8, 0.85, 0.9, 0.95, 1], \n",
    "                [0.55, 0.66, 0.75, 0.85, 1]]\n",
    "    # 降低比例\n",
    "    indexes = [[0.8, 0.6, 0.3, 0.1], [0.8, 0.7, 0.3, 0.1], \n",
    "              [0.8, 0.75, 0.6, 0.5, 0.3, 0.1, 0.03], [0.9, 0.85, 0.7, 0.3], \n",
    "              [0.8, 0.7, 0.3, 0.1]]\n",
    "    for i in range(len(columns)):\n",
    "        for k in range(len(quantiles[i]) - 1):\n",
    "            standard1 = df_wide.loc[df_wide['normal_lesson_log_count'] > 0, \n",
    "                                    columns[i]].quantile(quantiles[i][k])\n",
    "            standard2 = df_wide.loc[df_wide['normal_lesson_log_count'] > 0, \n",
    "                                    columns[i]].quantile(quantiles[i][k + 1])\n",
    "            # 降低正常上课的数量\n",
    "            df_wide.loc[(df_wide['normal_lesson_log_count'] > 0) & \n",
    "                (df_wide[columns[i]] > standard1) & (df_wide[columns[i]] <= standard2), \n",
    "                cache_columns[i]] = df_wide['normal_lesson_log_count'] * indexes[i][k]\n",
    "            # 新老师因为平滑原因，所以再复原，不惩罚\n",
    "            df_wide.loc[(df_wide['normal_lesson_log_count'] > 0) & \n",
    "                (df_wide[columns[i]] > standard1) & (df_wide[columns[i]] <= standard2) & \n",
    "                (df_wide[counts[i]] == math.log(2, 10)) & \n",
    "                (df_wide['normal_lesson_log_count'] <= 8), \n",
    "                cache_columns[i]] = df_wide['normal_lesson_log_count']\n",
    "    # 从5行cache_colume中取最小值\n",
    "    df_wide['normal_lesson_log_count_processed'] = df_wide[cache_columns].min(axis=1)\n",
    "    # 大小方向统一化\n",
    "    # 重新计算四个percent\n",
    "    df_wide['late_lesson_log_percent_processed'] = df_wide['late_lesson_log_count'] / df_wide['normal_lesson_log_count_processed']\n",
    "    df_wide['no_show_lesson_log_percent_processed'] = df_wide['no_show_lesson_log_count'] / df_wide['normal_lesson_log_count_processed']\n",
    "    df_wide['abnormal_lesson_log_percent_processed'] = df_wide['abnormal_lesson_log_count'] / df_wide['normal_lesson_log_count_processed']\n",
    "    df_wide['ask_for_leave_log_percent_processed'] = df_wide['ask_for_leave_log_count'] / df_wide['normal_lesson_log_count_processed']\n",
    "    df_wide['normal_log_lesson_per_week'] = df_wide['normal_lesson_log_count_processed'] / (df_wide['lesson_time_range']) \n",
    "    # 取倒数\n",
    "    rcp = ['late_lesson_log_processed', 'no_show_lesson_log_processed', \n",
    "           'abnormal_lesson_log_processed', 'ask_for_leave_log_processed', \n",
    "           'stu_comment_log_bad_behavior_processed']\n",
    "    cols = ['late_lesson_log_percent_processed', 'no_show_lesson_log_percent_processed', \n",
    "            'abnormal_lesson_log_percent_processed', 'ask_for_leave_log_percent_processed', \n",
    "            'stu_comment_log_bad_behavior']\n",
    "    for i in range(len(rcp)):\n",
    "        df_wide[rcp[i]] = 1 / df_wide[cols[i]]\n",
    "    # 修正老师上课数量少但好评较多的情况（如老师id642）\n",
    "    df_wide['stu_comment_log_good_behavior_processed'] = df_wide['stu_comment_log_good_behavior'] / ( \n",
    "                                df_wide['normal_lesson_log_count_all']\n",
    "                                + df_wide['late_lesson_log_count_all'] \n",
    "                                + df_wide['no_show_lesson_log_count_all'] \n",
    "                                + df_wide['ask_for_leave_log_count_all'] \n",
    "                                + df_wide['abnormal_lesson_log_count_all'])                    \n",
    "    df_wide['stu_comment_log_bad_behavior_processed'] = df_wide['stu_comment_log_bad_behavior'] / (\n",
    "                                df_wide['normal_lesson_log_count_all']\n",
    "#                                 + df_wide['late_lesson_log_count_all'] \n",
    "#                                 + df_wide['no_show_lesson_log_count_all'] \n",
    "#                                 + df_wide['ask_for_leave_log_count_all'] \n",
    "#                                 + df_wide['abnormal_lesson_log_count_all']\n",
    "                                    )\n",
    "    # 修正老师请假次数过多，但提前请假天数指标过好的情况（如老师id642） \n",
    "    columns = ['advanced_days_log_mean', 'advanced_days_max']\n",
    "    quantiles = [0.6, 0.66, 0.7, 0.75, 0.77, 0.8, 0.85, 1]\n",
    "    indexes = [0.9, 0.8, 0.7, 0.5, 0.3, 0.1, 0.05]\n",
    "    for i in range(len(columns)):\n",
    "        for k in range(len(quantiles) - 1):\n",
    "            percent1 = df_wide.loc[df_wide['normal_lesson_log_count'] > 0, \n",
    "                                'log_ask_for_leave/log_normal_lesson'].quantile(quantiles[k])\n",
    "            percent2 = df_wide.loc[df_wide['normal_lesson_log_count'] > 0, \n",
    "                                'log_ask_for_leave/log_normal_lesson'].quantile(quantiles[k + 1])\n",
    "            df_wide.loc[(df_wide['normal_lesson_log_count'] > 0) & \n",
    "                        (df_wide['log_ask_for_leave/log_normal_lesson'] > percent1) & \n",
    "                        (df_wide['log_ask_for_leave/log_normal_lesson'] <= percent2), \n",
    "                        columns[i]] = df_wide[columns[i]] * indexes[k]\n",
    "    # 无上课记录老师\n",
    "    columns = list(df_wide.columns)\n",
    "    columns.pop(columns.index('awj_teacher_id'))\n",
    "    for itm in columns:\n",
    "        df_wide.loc[df_wide['normal_lesson_log_count'] == 0, itm] = 0\n",
    "    # 只取有行为数据的\n",
    "    df_wide_final = df_wide.loc[df_wide['normal_lesson_log_count'] > 0]\n",
    "    # delete columns\n",
    "    df_wide_final.drop(['advanced_days_std', 'teacher_score_std', \n",
    "                  'advanced_days_min', 'lesson_time_range', \n",
    "                  'normal_lesson_log_count_all', 'no_show_lesson_log_count_all', \n",
    "                  'abnormal_lesson_log_count_all', 'late_lesson_log_count_all', \n",
    "                  'ask_for_leave_log_count_all', 'old_new_teacher', \n",
    "                  'teacher_qc_count', 'normal_lesson_log_count', 'late_lesson_log_count', \n",
    "                  'no_show_lesson_log_count', 'abnormal_lesson_log_count', \n",
    "                  'ask_for_leave_log_count', 'stu_comment_log_good_behavior', \n",
    "                  'stu_comment_log_bad_behavior', \n",
    "                  'log_ask_for_leave/log_normal_lesson',  'abnormal_lesson_log_percent',\n",
    "                  'late_lesson_log_percent', 'no_show_lesson_log_percent', \n",
    "                  'ask_for_leave_log_percent', 'abnormal_all_log_count', \n",
    "                  'late_lesson_log_percent_processed', 'no_show_lesson_log_percent_processed', \n",
    "                  'abnormal_lesson_log_percent_processed', 'ask_for_leave_log_percent_processed', \n",
    "                  'normal_lesson_log_count_processed', 'abnormal_all_log_percent', \n",
    "                  'normal_lesson_log_count_processed_ask_for_leave_cahce1', \n",
    "                  'normal_lesson_log_count_processed_late_lesson_cache2', \n",
    "                  'normal_lesson_log_count_processed_no_show_cache3', \n",
    "                  'normal_lesson_log_count_processed_abnormal_lesson_cache4', \n",
    "                  'normal_lesson_log_count_processed_abnormal_all_cahce5',                                        \n",
    "                  'normal_log_lesson_per_week', \n",
    "                  'stu_comment_log_bad_behavior_processed'], \n",
    "                   axis=1, inplace=True)\n",
    "    # save\n",
    "    df_wide_final.to_csv(path + 'df_wide_log_final.csv', sep=',', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1012,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fa_index1</th>\n",
       "      <th>fa_index2</th>\n",
       "      <th>fa_index3</th>\n",
       "      <th>fa_index4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.067965</td>\n",
       "      <td>0.007287</td>\n",
       "      <td>0.535777</td>\n",
       "      <td>0.057239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.081179</td>\n",
       "      <td>0.007034</td>\n",
       "      <td>0.541467</td>\n",
       "      <td>0.043481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.021609</td>\n",
       "      <td>0.338660</td>\n",
       "      <td>0.003847</td>\n",
       "      <td>-0.008771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.046738</td>\n",
       "      <td>0.344282</td>\n",
       "      <td>0.012750</td>\n",
       "      <td>-0.010007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.035079</td>\n",
       "      <td>0.348230</td>\n",
       "      <td>0.003747</td>\n",
       "      <td>-0.018199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.283483</td>\n",
       "      <td>-0.024297</td>\n",
       "      <td>-0.030890</td>\n",
       "      <td>-0.024959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.318853</td>\n",
       "      <td>-0.032983</td>\n",
       "      <td>-0.056064</td>\n",
       "      <td>0.024066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.307936</td>\n",
       "      <td>-0.026679</td>\n",
       "      <td>-0.050784</td>\n",
       "      <td>0.083130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.293590</td>\n",
       "      <td>-0.038004</td>\n",
       "      <td>-0.083815</td>\n",
       "      <td>-0.077168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.002655</td>\n",
       "      <td>-0.017316</td>\n",
       "      <td>0.062766</td>\n",
       "      <td>1.001195</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fa_index1  fa_index2  fa_index3  fa_index4\n",
       "0  -0.067965   0.007287   0.535777   0.057239\n",
       "1  -0.081179   0.007034   0.541467   0.043481\n",
       "2  -0.021609   0.338660   0.003847  -0.008771\n",
       "3  -0.046738   0.344282   0.012750  -0.010007\n",
       "4  -0.035079   0.348230   0.003747  -0.018199\n",
       "5   0.283483  -0.024297  -0.030890  -0.024959\n",
       "6   0.318853  -0.032983  -0.056064   0.024066\n",
       "7   0.307936  -0.026679  -0.050784   0.083130\n",
       "8   0.293590  -0.038004  -0.083815  -0.077168\n",
       "9   0.002655  -0.017316   0.062766   1.001195"
      ]
     },
     "execution_count": 1012,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FA_indexs\n",
    "fa_index = pd.read_excel(path + 'fa_indexs.xlsx')\n",
    "fa_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1013,
   "metadata": {},
   "outputs": [],
   "source": [
    "fa_index = fa_index.as_matrix()\n",
    "df_wide_matrix = deepcopy(df_wide_final)\n",
    "df_wide_matrix.drop(['awj_teacher_id'], axis=1, inplace=True)\n",
    "df_wide_matrix = df_wide_matrix.as_matrix()\n",
    "# df_wide标准化\n",
    "df_wide_matrix = preprocessing.scale(df_wide_matrix)\n",
    "# 每个老师的各因子得分\n",
    "fa_score = np.dot(df_wide_matrix, fa_index)\n",
    "# 主成分贡献率\n",
    "var = np.array([[0.37591 / 0.88651], \n",
    "                [0.26337 / 0.88651], \n",
    "                [0.15250 / 0.88651], \n",
    "                [0.09473 / 0.88651]])\n",
    "# 每个老师的最终得分\n",
    "final_score = np.dot(fa_score, var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1015,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5: 0.39932723159523076 4: -0.06554925390984362 3: -0.3866192561701031 2: -0.47629323522986805\n"
     ]
    }
   ],
   "source": [
    "# df格式\n",
    "teacher_fa_score = np.hstack((fa_score, final_score))\n",
    "teacher_fa_score = pd.DataFrame(teacher_fa_score)\n",
    "teacher_fa_score['awj_teacher_id'] = list(df_wide_final['awj_teacher_id'])\n",
    "teacher_fa_score.rename(columns={0: 'teacher_behavior_score', 1: 'teacher_qc_score', \n",
    "                                 2:'teacher_attitude_score', 3: 'student_comment_good_score', \n",
    "                                 4: 'final_score'}, inplace=True)\n",
    "# 星级映射(去除过去一段时间周期内没上过课的老师)\n",
    "teacher_fa_score = teacher_fa_score.sort_values(by='final_score', ascending=0)\n",
    "# 业务要求的分位数\n",
    "star_5 = teacher_fa_score['final_score'].quantile(0.8)\n",
    "star_4 = teacher_fa_score['final_score'].quantile(0.5)\n",
    "star_3 = teacher_fa_score['final_score'].quantile(0.2)\n",
    "star_2 = teacher_fa_score['final_score'].quantile(0.1)\n",
    "print('5:', star_5, '4:', star_4, '3:', star_3, '2:', star_2)\n",
    "teacher_fa_score.loc[teacher_fa_score['final_score'] <= star_2, 'star'] = 1\n",
    "teacher_fa_score.loc[(teacher_fa_score['final_score'] > star_2) & \n",
    "                     (teacher_fa_score['final_score'] <= star_3), 'star'] = 2\n",
    "teacher_fa_score.loc[(teacher_fa_score['final_score'] > star_3) & \n",
    "                     (teacher_fa_score['final_score'] <= star_4), 'star'] = 3\n",
    "teacher_fa_score.loc[(teacher_fa_score['final_score'] > star_4) & \n",
    "                     (teacher_fa_score['final_score'] <= star_5), 'star'] = 4\n",
    "teacher_fa_score.loc[teacher_fa_score['final_score'] > star_5, 'star'] = 5\n",
    "# 拼回去\n",
    "teacher_fa_score = pd.merge(teacher_fa_score, df_wide[\n",
    "    ['awj_teacher_id', 'normal_lesson_log_count']], on='awj_teacher_id', how='right')\n",
    "teacher_fa_score.fillna(value=0, inplace=True)\n",
    "# 没上过课的老老师都统一补为3星\n",
    "teacher_fa_score['star'] = teacher_fa_score['star'].replace({0: 3})\n",
    "teacher_fa_score.to_csv(path + 'teacher_star.csv', sep=',', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
