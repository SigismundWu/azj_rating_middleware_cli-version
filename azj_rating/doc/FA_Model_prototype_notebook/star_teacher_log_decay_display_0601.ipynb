{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1378,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas.tseries.offsets import *\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import math\n",
    "from copy import deepcopy\n",
    "import json\n",
    "from itertools import combinations, permutations\n",
    "import warnings\n",
    "\n",
    "% matplotlib inline\n",
    "pd.set_option('max_columns', 100)\n",
    "pd.set_option('max_rows', 500)\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1379,
   "metadata": {},
   "outputs": [],
   "source": [
    "def teacher_qc_score(start_time, end_time, df_qc, class_type_name_special, hq_name_special):\n",
    "    # 筛选条件\n",
    "    df_qc = df_qc.loc[(~df_qc['class_type_name'].isin(class_type_name_special)) & \n",
    "                    (~df_qc['hq_name'].isin(hq_name_special)) & \n",
    "                    (df_qc['start_time'] >= start_time) & (df_qc['end_time'] <= end_time)]\n",
    "    # log score-mean\n",
    "    df_qc['decay_index'] = ((end_time - df_qc['score_recorded_at']).dt.total_seconds()) / (3600 * 24) \n",
    "    df_qc.loc[df_qc['decay_index'] < 0, 'decay_index'] = 0 # qc时间有时会在end_time之后造成负值\n",
    "    df_qc['decay_index'] = df_qc['decay_index'] + 2 # log计算，防止0值+1;取倒数+1，防止无穷情况\n",
    "    df_qc['decay_index'] = df_qc['decay_index'].apply(lambda x: math.log(x, 10))\n",
    "    df_qc['decay_index'] = 1 / df_qc['decay_index']\n",
    "    df_qc['log_decay_score'] = df_qc['score'] * df_qc['decay_index']\n",
    "    df_teacher_log_score = df_qc.groupby(['awj_teacher_id'], \n",
    "                        as_index=False).agg({'log_decay_score': np.sum, 'decay_index': np.sum})\n",
    "    df_teacher_log_score['log_decay_score_mean'] = df_teacher_log_score['log_decay_score'] / df_teacher_log_score['decay_index']\n",
    "    df_teacher_log_score = df_teacher_log_score[['awj_teacher_id', 'log_decay_score_mean']]\n",
    "    # score\n",
    "    df_teacher_score = df_qc.groupby(['awj_teacher_id'], \n",
    "                as_index=False)['score'].agg(['max', 'min', 'count', np.std]) \n",
    "    # std missing\n",
    "    df_teacher_score.loc[df_teacher_score['std'].isnull(), 'std'] = df_teacher_score['std'].mean()\n",
    "    df_teacher_score.rename(columns={'max': 'teacher_score_max', 'min': 'teacher_score_min', \n",
    "                        'count': 'teacher_qc_count', 'std': 'teacher_score_std'}, inplace=True)\n",
    "    df_teacher_score.reset_index(inplace=True)\n",
    "    # merge\n",
    "    df_qc_res = pd.merge(df_teacher_score, df_teacher_log_score, on='awj_teacher_id', how='left')\n",
    "    return df_qc_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1380,
   "metadata": {},
   "outputs": [],
   "source": [
    "def teacher_behavior(start_time, end_time, df_teacher_behavior, \n",
    "                         class_type_name_special, hq_name_special):\n",
    "    # 筛选条件\n",
    "    df_teacher_behavior = df_teacher_behavior.loc[\n",
    "                    (~df_teacher_behavior['上课类型'].isin(class_type_name_special)) & \n",
    "                    (~df_teacher_behavior['机构'].isin(hq_name_special)) & \n",
    "                    (df_teacher_behavior['start_time'] >= start_time) & \n",
    "                    (df_teacher_behavior['end_time'] <= end_time) & \n",
    "                    (~df_teacher_behavior['teacher_status_for_lesson'].isin(['system_failure']))]\n",
    "    # 预处理\n",
    "    df_teacher_behavior['lesson_count'] = ((df_teacher_behavior['end_time'] - \n",
    "                        df_teacher_behavior['start_time']).dt.total_seconds()) / 3600 * 2\n",
    "    df_teacher_behavior.loc[df_teacher_behavior['teacher_status_for_lesson'] == 'no_show', \n",
    "                            'ask_for_leave_advanced_minutes'] = 0\n",
    "    df_teacher_behavior['ask_for_leave_advanced_days'] = df_teacher_behavior['ask_for_leave_advanced_minutes'] / (60 * 24)\n",
    "    # 天数衰减\n",
    "    df_teacher_behavior['decay_index'] = ((end_time - \n",
    "            df_teacher_behavior['start_time']).dt.total_seconds()) / (3600 * 24) \n",
    "    df_teacher_behavior.loc[df_teacher_behavior['decay_index'] < 0, 'decay_index'] = 0\n",
    "    # log计算，防止0值+1;取倒数+1，防止无穷情况\n",
    "    df_teacher_behavior['decay_index'] = df_teacher_behavior['decay_index'] + 2\n",
    "    df_teacher_behavior['decay_index'] = df_teacher_behavior['decay_index'].apply(lambda x: math.log(x, 10))\n",
    "    df_teacher_behavior['decay_index'] = 1 / df_teacher_behavior['decay_index']\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # count lesson types\n",
    "    df_teacher_behavior_res = df_teacher_behavior[['awj_teacher_id']]\n",
    "    df_teacher_behavior_res.drop_duplicates(keep='first', inplace=True)\n",
    "    types = ['normal_lesson', 'late', 'no_show', 'abnormal_lesson', 'ask_for_leave']\n",
    "    for itm in types:\n",
    "        df_count = df_teacher_behavior.loc[\n",
    "            df_teacher_behavior['teacher_status_for_lesson'].isin([itm])]\n",
    "        df_count['log_lesson_count'] = df_count['lesson_count'] * df_count['decay_index']\n",
    "        df_count = df_count.groupby(['awj_teacher_id'], as_index=False)['log_lesson_count'].sum()\n",
    "        df_count.reset_index()\n",
    "        if (itm.find('ask_for_leave') > -1) | (itm.find('lesson') > -1):\n",
    "            df_count.rename(columns={'log_lesson_count': itm + '_log_count'}, inplace=True)\n",
    "        else:\n",
    "            df_count.rename(columns={'log_lesson_count': itm + '_lesson_log_count'}, inplace=True)\n",
    "        df_teacher_behavior_res = pd.merge(df_teacher_behavior_res, df_count, \n",
    "                                          on='awj_teacher_id', how='left')\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    # ask for leave advanced minutes\n",
    "    df_advanced_days = df_teacher_behavior.loc[\n",
    "        df_teacher_behavior['teacher_status_for_lesson'].isin(['ask_for_leave', 'no_show'])]  \n",
    "    df_advanced_days['ask_for_leave_advanced_log_days'] = df_advanced_days['decay_index'] * df_advanced_days['ask_for_leave_advanced_days']\n",
    "    # 求均值\n",
    "    df_advanced_days_mean = df_advanced_days.groupby(['awj_teacher_id'], as_index=False).agg(\n",
    "        {'ask_for_leave_advanced_log_days': np.sum, 'decay_index': np.sum})\n",
    "    df_advanced_days_mean.reset_index(inplace=True)\n",
    "    df_advanced_days_mean['advanced_days_log_mean'] = df_advanced_days_mean['ask_for_leave_advanced_log_days'] / df_advanced_days_mean['decay_index'] \n",
    "    df_advanced_days_mean = df_advanced_days_mean[['awj_teacher_id', 'advanced_days_log_mean']]\n",
    "    # 求最大最小值及方差\n",
    "    df_advanced_days_others = df_advanced_days.groupby(['awj_teacher_id'], \n",
    "            as_index=False)['ask_for_leave_advanced_days'].agg(['min', 'max', 'std'])\n",
    "    df_advanced_days_others.reset_index(inplace=True)\n",
    "    df_advanced_days_others.loc[df_advanced_days_others['std'].isnull(), \n",
    "                                'std'] = df_advanced_days_others['std'].mean()\n",
    "    df_advanced_days_others.rename(columns={'min': 'advanced_days_min', \n",
    "                    'max': 'advanced_days_max', 'std': 'advanced_days_std'}, inplace=True)\n",
    "    df_advanced_days = pd.merge(df_advanced_days_mean, df_advanced_days_others, \n",
    "                               on='awj_teacher_id', how='left')\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    df_teacher_behavior_res = pd.merge(df_teacher_behavior_res, df_advanced_days, \n",
    "                                                       on='awj_teacher_id', how='left')\n",
    "    # fill 0\n",
    "    columns = ['normal_lesson_log_count', 'late_lesson_log_count', 'no_show_lesson_log_count', \n",
    "               'abnormal_lesson_log_count', 'ask_for_leave_log_count', 'advanced_days_log_mean', \n",
    "               'advanced_days_min', 'advanced_days_max', 'advanced_days_std']\n",
    "    for itm in columns:\n",
    "        df_teacher_behavior_res[itm].fillna(value=0, inplace=True)\n",
    "    return df_teacher_behavior_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1381,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stu_comment(start_time, end_time, df_stu_comment, class_type_name_special, hq_name_special):\n",
    "    # 筛选条件：时间筛选条件由于筛选后数量过少，所以采用全量数据\n",
    "    df_stu_comment = df_stu_comment.loc[~df_stu_comment['机构'].isin(hq_name_special)]\n",
    "    # 天数衰减\n",
    "    df_stu_comment['decay_index'] = ((end_time - \n",
    "            df_stu_comment['评价时间']).dt.total_seconds()) / (3600 * 24) \n",
    "    df_stu_comment.loc[df_stu_comment['decay_index'] < 0, 'decay_index'] = 0\n",
    "    # log计算，防止0值+1;取倒数+1，防止无穷情况\n",
    "    df_stu_comment['decay_index'] = df_stu_comment['decay_index'] + 2\n",
    "    df_stu_comment['decay_index'] = df_stu_comment['decay_index'].apply(lambda x: math.log(x, 10))\n",
    "    df_stu_comment['decay_index'] = 1 / df_stu_comment['decay_index']\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # 正面标签统计:有时一次课有多个好评标签，导致有些老师上课次数很少，但好评标签总量超过次数本身，不公平\n",
    "    # 所以此处每堂课不管有几个好评标签，都算做一个好评统计\n",
    "    df_good_label = df_stu_comment.loc[(df_stu_comment['学生评价星级'].isin(['5-star', '4-star'])) & \n",
    "            (df_stu_comment['标签内容'].isin(['老师有耐心', '课堂氛围好', '课程生动有趣', '互动丰富']))]\n",
    "    df_good_label = df_good_label.groupby(['评价id'], as_index=False).first()\n",
    "    df_good_label['标签内容'] = 1\n",
    "    df_good_label['标签内容_processed'] = df_good_label['标签内容'] * df_good_label['decay_index']\n",
    "    df_good_label = df_good_label.groupby(['awj_teacher_id'], \n",
    "                            as_index=False)['标签内容_processed'].sum()\n",
    "    df_good_label.rename(columns={'标签内容_processed': 'stu_comment_log_good_behavior'}, inplace=True)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # 负面标签统计：主观原因。客观原因---产品说环境原因可能是因为是视频供应商平台或学生自己网络问题，所以不应该计入\n",
    "    # 去除4星及5星的数据，理论上，四星五星无负面评价，有的都是系统bug导致\n",
    "    df_bad_label = df_stu_comment.loc[(~df_stu_comment['学生评价星级'].isin(['5-star', '4-star'])) & \n",
    "                    (df_stu_comment['标签内容'].isin(['老师语速过快', '互动较少', \n",
    "                    '课堂氛围差', '未及时纠正错误', '老师缺乏耐心']))]\n",
    "    df_bad_label = df_bad_label.groupby(['评价id'], as_index=False).first()\n",
    "    df_bad_label['标签内容'] = 1\n",
    "    df_bad_label['标签内容_processed'] = df_bad_label['标签内容'] * df_bad_label['decay_index']\n",
    "    df_bad_label = df_bad_label.groupby(['awj_teacher_id'], \n",
    "                                as_index=False)['标签内容_processed'].sum()\n",
    "    df_bad_label.rename(columns={'标签内容_processed': 'stu_comment_log_bad_behavior'}, inplace=True)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # merge\n",
    "    df_stu_comment_res = pd.merge(df_good_label, df_bad_label, on='awj_teacher_id', how='outer')\n",
    "    df_stu_comment_res['stu_comment_log_bad_behavior'].fillna(value=0, inplace=True)\n",
    "    df_stu_comment_res['stu_comment_log_good_behavior'].fillna(value=0, inplace=True)\n",
    "    return df_stu_comment_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1382,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start_time: 2018-01-30 23:59:59.964000 \n",
      " end_time: 2018-04-30 23:59:59.964000 \n",
      "\n",
      "df_teacher_monitoring key check_duplicate no(awj_teacher_id, awjcls_lesson_id): 0 \n",
      "\n",
      "df_qc_before drop duplicates: (29311, 17)\n",
      "df_qc_drop duplicates: (24184, 17)\n",
      "df_qc key check_duplicate no(awj_teacher_id, awjcls_lesson_id): 0 \n",
      "\n",
      "df_teacher_behavior shape: (241621, 13)\n",
      "df_teacher_behavior shape(teacher_id+lesson_id as key:) (241469, 13)\n",
      "df_teacher_behavior shape(no abnormal_type=4, 5) (241467, 13)\n",
      "df_teacher_behavior key check_duplicate no(awj_teacher_id, awj_lesson_id): 0 \n",
      "\n",
      "df_teacher_info key check duplicate no(awj_teacher_id): 0 \n",
      "\n",
      "\n",
      " no_show_lesson_log_percent :\n",
      "0.1 : 0.0018820002286611525\n",
      "0.15 : 0.0025431080331542824\n",
      "0.2 : 0.0031769838818104766\n",
      "0.25 : 0.003705200635063426\n",
      "0.3 : 0.004781703634328\n",
      "0.33 : 0.0055724158308541345\n",
      "0.5 : 0.013125502042295185\n",
      "0.55 : 0.01351799396865686\n",
      "0.6 : 0.01534448780842574\n",
      "0.66 : 0.02405211253718694\n",
      "0.7 : 0.03423670050529353\n",
      "0.75 : 0.045772998822658326\n",
      "0.77 : 0.06509476640229833\n",
      "0.8 : 0.08591381207822764\n",
      "0.83 : 0.1298150098644584\n",
      "0.85 : 0.21725830948671315\n",
      "0.9 : 1.0\n",
      "0.92 : 1.0\n",
      "0.95 : 1.0\n",
      "1 : 34.724958155987984\n",
      "\n",
      " late_lesson_log_percent :\n",
      "0.1 : 0.0019277004638405377\n",
      "0.15 : 0.0023969437409609765\n",
      "0.2 : 0.002899541900620673\n",
      "0.25 : 0.003409087411947743\n",
      "0.3 : 0.004236821534997881\n",
      "0.33 : 0.0048007329486942476\n",
      "0.5 : 0.013394027493402202\n",
      "0.55 : 0.017665483845649414\n",
      "0.6 : 0.026380981294308894\n",
      "0.66 : 0.027425448961015626\n",
      "0.7 : 0.03363138369746561\n",
      "0.75 : 0.045861577260283365\n",
      "0.77 : 0.060953835065019744\n",
      "0.8 : 0.10157801404934581\n",
      "0.83 : 0.1434039789677291\n",
      "0.85 : 0.17995244362227786\n",
      "0.9 : 1.0\n",
      "0.92 : 1.0\n",
      "0.95 : 1.0\n",
      "1 : 1.3932692532782813\n",
      "\n",
      " abnormal_lesson_log_percent :\n",
      "0.1 : 0.0018213592377323289\n",
      "0.15 : 0.0021678220894299836\n",
      "0.2 : 0.0026963887175836935\n",
      "0.25 : 0.003210541138409617\n",
      "0.3 : 0.003914534593275336\n",
      "0.33 : 0.004280886329111767\n",
      "0.5 : 0.006798842326906607\n",
      "0.55 : 0.00833909467532465\n",
      "0.6 : 0.010878854544975648\n",
      "0.66 : 0.014489764734734413\n",
      "0.7 : 0.018853351772578023\n",
      "0.75 : 0.03192758410405218\n",
      "0.77 : 0.036781449075203226\n",
      "0.8 : 0.04496610786248227\n",
      "0.83 : 0.07213256675605445\n",
      "0.85 : 0.09951342197190466\n",
      "0.9 : 0.5888460203597046\n",
      "0.92 : 1.0\n",
      "0.95 : 1.0\n",
      "1 : 1.0\n",
      "\n",
      " ask_for_leave_log_percent :\n",
      "0.1 : 0.0021021518725396703\n",
      "0.15 : 0.0034881180851116583\n",
      "0.2 : 0.0056498972034903245\n",
      "0.25 : 0.01013444227431403\n",
      "0.3 : 0.0164815987493893\n",
      "0.33 : 0.02226574190652149\n",
      "0.5 : 0.06917809910678925\n",
      "0.55 : 0.10213242494096098\n",
      "0.6 : 0.14536085122628858\n",
      "0.66 : 0.15616284102621078\n",
      "0.7 : 0.24567321494484834\n",
      "0.75 : 0.39582362847490893\n",
      "0.77 : 0.5157587344524206\n",
      "0.8 : 0.8984389746547492\n",
      "0.83 : 1.7138509196008227\n",
      "0.85 : 2.559660125973121\n",
      "0.9 : 7.804454542563757\n",
      "0.92 : 16.785847168069882\n",
      "0.95 : 56.53133305951607\n",
      "1 : 498.5103367944088\n",
      "\n",
      " abnormal_all_log_percent :\n",
      "0.1 : 0.0\n",
      "0.15 : 0.004365447103838168\n",
      "0.2 : 0.010972036355764776\n",
      "0.25 : 0.020230414558404505\n",
      "0.3 : 0.03023386681670545\n",
      "0.33 : 0.03598893213251049\n",
      "0.5 : 0.10045992074017371\n",
      "0.55 : 0.13757317273947928\n",
      "0.6 : 0.18558990659546876\n",
      "0.66 : 0.25749301554787635\n",
      "0.7 : 0.25749301554787635\n",
      "0.75 : 0.3570556047082923\n",
      "0.77 : 0.4352127493000146\n",
      "0.8 : 0.5311883766066863\n",
      "0.83 : 0.6361019537834098\n",
      "0.85 : 0.7098591841512756\n",
      "0.9 : 0.8940256071893526\n",
      "0.92 : 0.9497519780811422\n",
      "0.95 : 0.9830057804817006\n",
      "1 : 0.9979940235413566\n",
      "\n",
      " log_ask_for_leave/log_normal_lesson :\n",
      "0.1 : 0.0\n",
      "0.15 : 0.0\n",
      "0.2 : 0.0\n",
      "0.25 : 0.0\n",
      "0.3 : 0.0\n",
      "0.33 : 0.006392348387957943\n",
      "0.5 : 0.05662313640733727\n",
      "0.55 : 0.08430050802828482\n",
      "0.6 : 0.13388179063779346\n",
      "0.66 : 0.285631366000062\n",
      "0.7 : 0.4207988290328804\n",
      "0.75 : 1.1304812396587676\n",
      "0.77 : 1.7004693414897436\n",
      "0.8 : 3.113120312358871\n",
      "0.83 : 5.6000587730453555\n",
      "0.85 : 9.81737749019925\n",
      "0.9 : 9.81737749019925\n",
      "0.92 : 15.785847168069882\n",
      "0.95 : 55.53133305951607\n",
      "1 : 497.5103367944088\n",
      "\n",
      " advanced_days_log_mean :\n",
      "0.1 : 2.897702319082998\n",
      "0.15 : 7.990223104413349\n",
      "0.2 : 16.695578942820127\n",
      "0.25 : 25.42325632036503\n",
      "0.3 : 31.7944021800544\n",
      "0.33 : 31.794402180054398\n",
      "0.5 : 46.4422297426811\n",
      "0.55 : 46.4422297426811\n",
      "0.6 : 46.44222974268111\n",
      "0.66 : 46.4422297426811\n",
      "0.7 : 46.4422297426811\n",
      "0.75 : 47.069867833231896\n",
      "0.77 : 51.0820475294406\n",
      "0.8 : 56.00794275022796\n",
      "0.83 : 62.90559720525198\n",
      "0.85 : 74.46360636640158\n",
      "0.9 : 95.71417339209782\n",
      "0.92 : 109.36118174536115\n",
      "0.95 : 134.21604170546357\n",
      "1 : 184.92638888888888\n",
      "\n",
      " advanced_days_max :\n",
      "0.1 : 6.077361111111112\n",
      "0.15 : 15.550138888888892\n",
      "0.2 : 34.00541666666666\n",
      "0.25 : 43.91388888888889\n",
      "0.3 : 48.73240649064907\n",
      "0.33 : 48.73240649064907\n",
      "0.5 : 71.18365067333292\n",
      "0.55 : 71.18365067333292\n",
      "0.6 : 71.18365067333292\n",
      "0.66 : 71.18365067333292\n",
      "0.7 : 71.18365067333292\n",
      "0.75 : 76.63368055555554\n",
      "0.77 : 83.30833333333334\n",
      "0.8 : 93.47458333333333\n",
      "0.83 : 105.40383333333334\n",
      "0.85 : 123.04763888888888\n",
      "0.9 : 150.51138888888886\n",
      "0.92 : 168.58983333333342\n",
      "0.95 : 178.3979861111111\n",
      "1 : 221.8513888888889\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    path = '/Users/roger.zhou/Downloads/星级老师/'\n",
    "    end_time = pd.to_datetime(datetime.datetime.now().date()) + MonthEnd(n=-1) + DateOffset(hours=23.99999)\n",
    "    start_time = end_time - DateOffset(months=3)\n",
    "    class_type_name_special = ['Demo', '补课(非爱乐奇直属老师)', '托福班（30刀）', 'TOFEL', \n",
    "                              'VIP Writing/TOFEL（35刀）', 'Elite Pilot', 'Feeback Session', \n",
    "                              'New Teacher Test Class', '补课(爱乐奇直属老师)', 'Test Class', \n",
    "                              'Academic Meeting (Long)', 'Cur Experience Session-S', \n",
    "                              'Training-receiving', 'Cur Experience Session-L', \n",
    "                              'VIP Writing/TOFEL', 'Orientation Class', 'Academic Meeting', \n",
    "                              'Experience-receiving']\n",
    "    hq_name_special = ['test']\n",
    "    print('start_time:', start_time, '\\n', 'end_time:', end_time, '\\n')\n",
    "    \n",
    "    ##### 老师监控表 #####\n",
    "    df_teacher_monitoring = pd.read_csv(path + 'awj_teacher_monitoring.csv', encoding='utf-8', sep=',')\n",
    "    # dtypes\n",
    "    df_teacher_monitoring['awj_teacher_id'] = df_teacher_monitoring['awj_teacher_id'].astype('int')\n",
    "    df_teacher_monitoring['created_at'] = pd.to_datetime(df_teacher_monitoring['created_at'])\n",
    "    # drop duplicates\n",
    "    df_teacher_monitoring.drop_duplicates(\n",
    "                        subset=list(df_teacher_monitoring.columns), keep='first', inplace=True)\n",
    "    # sort\n",
    "    df_teacher_monitoring = df_teacher_monitoring.sort_values(\n",
    "                    by=['awj_teacher_id', 'awjcls_lesson_id', 'created_at'], ascending=[1, 1, 1])\n",
    "    # 该表只取abnormal_type为4，5的行，分别表示zoom崩溃和课件崩溃，非老师原因\n",
    "    df_teacher_monitoring = df_teacher_monitoring.loc[\n",
    "                    df_teacher_monitoring['abnormal_type'].isin([4, 5])]\n",
    "    df_teacher_monitoring = df_teacher_monitoring.groupby(\n",
    "                ['awj_teacher_id', 'awjcls_lesson_id', 'abnormal_type'], as_index=False).last()\n",
    "    # 唯一主键awj_teacher_id+awjcls_lesson_id check\n",
    "    cache = df_teacher_monitoring.groupby(['awj_teacher_id', 'awjcls_lesson_id'], \n",
    "                                      as_index=False)['abnormal_type'].count()\n",
    "    print('df_teacher_monitoring key check_duplicate no(awj_teacher_id, awjcls_lesson_id):', \n",
    "          cache.loc[cache['abnormal_type'] > 1].shape[0], '\\n')\n",
    "    \n",
    "    ##### 老师QC明细表 #####\n",
    "    df_qc = pd.read_csv(path + '老师qc明细.csv', encoding='utf-8', sep=',')\n",
    "    # dtypes\n",
    "    df_qc['awj_teacher_id'] = df_qc['awj_teacher_id'].astype('int')\n",
    "    df_qc['score_recorded_at'] = pd.to_datetime(df_qc['score_recorded_at'])\n",
    "    df_qc['assigned_at'] = pd.to_datetime(df_qc['assigned_at'])\n",
    "    df_qc['start_time'] = pd.to_datetime(df_qc['start_time'])\n",
    "    df_qc['end_time'] = pd.to_datetime(df_qc['end_time'])\n",
    "    print('df_qc_before drop duplicates:', df_qc.shape)\n",
    "    # drop duplicates-老师同一堂课有时会有多次qc，check后发现分数都一样，所以去重时按照以下字段去重即可\n",
    "    columns = ['awj_teacher_id', 'awjcls_lesson_id', 'score']\n",
    "    df_qc.drop_duplicates(subset=columns, keep='last', inplace=True)\n",
    "    print('df_qc_drop duplicates:', df_qc.shape)\n",
    "    # sort\n",
    "    df_qc = df_qc.sort_values(by=['awj_teacher_id', 'start_time'], ascending=[1, 1])\n",
    "    # 唯一主键awj_teacher_id+awjcls_lesson_id check\n",
    "    cache = df_qc.groupby(['awj_teacher_id', 'awjcls_lesson_id'], \n",
    "                                      as_index=False)['score'].count()\n",
    "    print('df_qc key check_duplicate no(awj_teacher_id, awjcls_lesson_id):', \n",
    "          cache.loc[cache['score'] > 1].shape[0], '\\n')\n",
    "    \n",
    "    ##### 老师行为表 #####\n",
    "    df_teacher_behavior = pd.read_csv(path + '老师行为信息明细.csv', sep=',', encoding='utf-8')\n",
    "    # dtypes\n",
    "    df_teacher_behavior['awj_teacher_id'] = df_teacher_behavior['awj_teacher_id'].astype('int')\n",
    "    df_teacher_behavior['start_time'] = pd.to_datetime(df_teacher_behavior['start_time'])\n",
    "    df_teacher_behavior['end_time'] = pd.to_datetime(df_teacher_behavior['end_time'])\n",
    "    df_teacher_behavior['actual_start_time'] = pd.to_datetime(df_teacher_behavior['actual_start_time'])\n",
    "    df_teacher_behavior['actual_end_time'] = pd.to_datetime(df_teacher_behavior['actual_end_time'])\n",
    "    df_teacher_behavior.drop_duplicates(subset=list(df_teacher_behavior.columns), inplace=True)\n",
    "    # sort\n",
    "    df_teacher_behavior = df_teacher_behavior.sort_values(by=[\n",
    "            'awj_teacher_id', 'awj_lesson_id', 'start_time', '积分变化'], ascending=[1, 1, 1, 1])\n",
    "    print('df_teacher_behavior shape:', df_teacher_behavior.shape)\n",
    "    # 老师id加lesson_id应该唯一，但有时有重复情况，因为有些老师先请了假，后来又来上课了，所以请假应该去除\n",
    "    df_teacher_behavior = df_teacher_behavior.groupby(\n",
    "                ['awj_teacher_id', 'awj_lesson_id'], as_index=False).last()\n",
    "    print('df_teacher_behavior shape(teacher_id+lesson_id as key:)', df_teacher_behavior.shape)\n",
    "    # 与monitoring表对比，去除老师abnormal_lesson细分为4，5状态下的课程记录\n",
    "    df_teacher_behavior = pd.merge(df_teacher_behavior, \n",
    "                    df_teacher_monitoring[['awj_teacher_id', 'awjcls_lesson_id', 'abnormal_type']], \n",
    "                    left_on=['awj_teacher_id', 'awj_lesson_id'], \n",
    "                    right_on=['awj_teacher_id', 'awjcls_lesson_id'], how='left')\n",
    "    index = df_teacher_behavior.loc[\n",
    "                    (df_teacher_behavior['teacher_status_for_lesson'] == 'abnormal_lesson') & \n",
    "                    (df_teacher_behavior['abnormal_type'].isin([4, 5]))].index\n",
    "    df_teacher_behavior = df_teacher_behavior.loc[~df_teacher_behavior.index.isin(list(index))]\n",
    "    df_teacher_behavior.drop(['awjcls_lesson_id', 'abnormal_type'], axis=1, inplace=True)\n",
    "    print('df_teacher_behavior shape(no abnormal_type=4, 5)', df_teacher_behavior.shape)\n",
    "    # 唯一主键awj_teacher_id+awjcls_lesson_id check\n",
    "    cache = df_teacher_behavior.groupby(['awj_teacher_id', 'awj_lesson_id'], \n",
    "                                      as_index=False)['start_time'].count()\n",
    "    print('df_teacher_behavior key check_duplicate no(awj_teacher_id, awj_lesson_id):', \n",
    "          cache.loc[cache['start_time'] > 1].shape[0], '\\n')\n",
    "    \n",
    "    ##### 老师信息表 #####\n",
    "    df_teacher_info = pd.read_csv(path + '老师基本信息.csv', sep=',', encoding='utf-8')\n",
    "    # dtypes\n",
    "    df_teacher_info['awj_teacher_id'] = df_teacher_info['awj_teacher_id'].astype(int)\n",
    "    df_teacher_info['创建时间'] = pd.to_datetime(df_teacher_info['创建时间'])\n",
    "    df_teacher_info['首次上架时间'] = pd.to_datetime(df_teacher_info['首次上架时间'])\n",
    "    df_teacher_info['首课时间'] = pd.to_datetime(df_teacher_info['首课时间'])\n",
    "    df_teacher_info.drop_duplicates(\n",
    "        subset=list(df_teacher_info.columns), keep='first', inplace=True)\n",
    "    # 根据业务要求只取某些type类型老师，其他去除\n",
    "    df_teacher_info = df_teacher_info.loc[df_teacher_info['teacher_type'].isin([\n",
    "                'booking&arrangement', 'arrangement_only', 'booking_only'])]\n",
    "    # sort\n",
    "    df_teacher_info = df_teacher_info.sort_values(by=['awj_teacher_id'], ascending=[1])\n",
    "    df_teacher_info = df_teacher_info[['awj_teacher_id', 'state', '创建时间', \n",
    "                                                           '首次上架时间', '首课时间']]\n",
    "    print('df_teacher_info key check duplicate no(awj_teacher_id):', \n",
    "          df_teacher_info.shape[0] - df_teacher_info['awj_teacher_id'].nunique(), '\\n')\n",
    "    \n",
    "    ##### 学生评价明细表(去重在函数内完成) #####\n",
    "    df_stu_comment = pd.read_csv(path + '学生评价明细.csv', sep=',', encoding='utf-8')\n",
    "    # dtypes\n",
    "    df_stu_comment['awj_teacher_id'] = df_stu_comment['awj_teacher_id'].astype(int)\n",
    "    df_stu_comment['评价时间'] = pd.to_datetime(df_stu_comment['评价时间'])\n",
    "    df_stu_comment.drop_duplicates(subset=list(df_stu_comment.columns), keep='first', inplace=True)\n",
    "    # sort\n",
    "    df_stu_comment = df_stu_comment.sort_values(by=[\n",
    "                    'awj_teacher_id', '评价时间'], ascending=[1, 1])  \n",
    "    \n",
    "    # 函数调用\n",
    "    df_qc_res = teacher_qc_score(start_time, end_time, df_qc, \n",
    "                                 class_type_name_special, hq_name_special)\n",
    "    df_teacher_behavior_res = teacher_behavior(start_time, \n",
    "                        end_time, df_teacher_behavior, class_type_name_special, hq_name_special)\n",
    "    df_stu_comment_res = stu_comment(start_time, end_time, df_stu_comment, \n",
    "                                     class_type_name_special, hq_name_special)\n",
    "    # 宽表\n",
    "    df_wide = pd.merge(df_teacher_info, df_teacher_behavior_res, on='awj_teacher_id', how='left')\n",
    "    df_wide = pd.merge(df_wide, df_qc_res, on='awj_teacher_id', how='left')\n",
    "    df_wide = pd.merge(df_wide, df_stu_comment_res, on='awj_teacher_id', how='left')\n",
    "    # 学生评价---采用全量数据，需用到全量老师上课数值\n",
    "    df_lesson_count_all = teacher_behavior(end_time - DateOffset(months=360), end_time, \n",
    "                            df_teacher_behavior, class_type_name_special, hq_name_special)\n",
    "    df_lesson_count_all = df_lesson_count_all[['awj_teacher_id', 'normal_lesson_log_count', \n",
    "                                        'late_lesson_log_count', 'no_show_lesson_log_count', \n",
    "                                        'ask_for_leave_log_count', 'abnormal_lesson_log_count']]\n",
    "    df_lesson_count_all.rename(columns={'normal_lesson_log_count': 'normal_lesson_log_count_all', \n",
    "                                    'late_lesson_log_count': 'late_lesson_log_count_all', \n",
    "                                    'no_show_lesson_log_count': 'no_show_lesson_log_count_all', \n",
    "                                    'ask_for_leave_log_count': 'ask_for_leave_log_count_all', \n",
    "                                    'abnormal_lesson_log_count': 'abnormal_lesson_log_count_all'}, \n",
    "                                    inplace=True)\n",
    "    df_wide = pd.merge(df_wide, df_lesson_count_all, on='awj_teacher_id', how='left')\n",
    "    # 有些老师没上过课，但请过假，此处为了让这些老师参加评分而非直接三星，所以将normal_lesson_log_count平滑处理\n",
    "    df_wide.loc[(df_wide['normal_lesson_log_count'] == 0) & \n",
    "            (df_wide['ask_for_leave_log_count'] > 0), 'normal_lesson_log_count'] = math.log(2, 10)\n",
    "    # 衍生新字段\n",
    "    df_wide['log_ask_for_leave/log_normal_lesson'] = df_wide['ask_for_leave_log_count'] / df_wide['normal_lesson_log_count']\n",
    "    df_wide['abnormal_all_log_count'] = (df_wide['no_show_lesson_log_count'] + \n",
    "                                      df_wide['late_lesson_log_count'] + \n",
    "                                      df_wide['abnormal_lesson_log_count'] + \n",
    "                                      df_wide['ask_for_leave_log_count'])\n",
    "    df_wide['abnormal_all_log_percent'] = (df_wide['abnormal_all_log_count']) / (\n",
    "                                      df_wide['normal_lesson_log_count'] + \n",
    "                                      df_wide['abnormal_all_log_count'])\n",
    "    df_wide['lesson_time_range'] = ((end_time - df_wide['首课时间']).dt.total_seconds()) / (3600 * 24) \n",
    "    df_wide.loc[df_wide['lesson_time_range'] == 0, 'lesson_time_range'] = ((end_time - df_wide['创建时间']).dt.total_seconds()) / (3600 * 24)  \n",
    "    # 判断是否是新老师\n",
    "    df_wide['old_new_teacher'] = 'old'\n",
    "    df_wide.loc[(df_wide['首课时间'].isnull()) & \n",
    "                (df_wide['state'].isin(['oboard', 'active'])), 'old_new_teacher'] = 'new'\n",
    "    # 缺失值填补\n",
    "    # 无用字段去除\n",
    "    df_wide.drop(['创建时间', '首次上架时间', '首课时间', 'state'], axis=1, inplace=True)\n",
    "    columns = list(df_wide.columns)\n",
    "    columns.pop(columns.index('awj_teacher_id'))\n",
    "    columns.pop(columns.index('old_new_teacher'))\n",
    "    # new teacher: mean\n",
    "    for itm in columns:\n",
    "        df_wide.loc[df_wide['old_new_teacher'] == 'new', itm] = df_wide.loc[\n",
    "            (df_wide['normal_lesson_log_count'] > 0), itm].mean()\n",
    "    # old teacher:0\n",
    "    df_wide.fillna(value=0, inplace=True)\n",
    "    new_teacher = df_wide.loc[df_wide['old_new_teacher'] == 'new', 'awj_teacher_id']\n",
    "    # 有些老师没有请过假，advanced_days字段为0，填为均值\n",
    "    df_wide.loc[(df_wide['ask_for_leave_log_count'] == 0) & (df_wide['normal_lesson_log_count'] > 0), \n",
    "        'advanced_days_max'] = df_wide.loc[(df_wide['advanced_days_max'] != 0) & \n",
    "                        df_wide['normal_lesson_log_count'] > 0, 'advanced_days_max'].mean()\n",
    "    df_wide.loc[(df_wide['ask_for_leave_log_count'] == 0) & (df_wide['normal_lesson_log_count'] > 0), \n",
    "        'advanced_days_log_mean'] = df_wide.loc[(df_wide['advanced_days_log_mean'] != 0) & \n",
    "                        df_wide['normal_lesson_log_count'] > 0, 'advanced_days_log_mean'].mean()\n",
    "    # 平滑\n",
    "    smooth = ['late_lesson_log_count', 'no_show_lesson_log_count', 'abnormal_lesson_log_count', \n",
    "              'ask_for_leave_log_count', 'stu_comment_log_bad_behavior']\n",
    "    for itm in smooth:\n",
    "        df_wide[itm] = df_wide[itm] + math.log(2, 10)\n",
    "    # 字段处理\n",
    "    # 比例计算\n",
    "    df_wide['late_lesson_log_percent'] = df_wide['late_lesson_log_count'] / df_wide['normal_lesson_log_count']\n",
    "    df_wide['no_show_lesson_log_percent'] = df_wide['no_show_lesson_log_count'] / df_wide['normal_lesson_log_count']\n",
    "    df_wide['abnormal_lesson_log_percent'] = df_wide['abnormal_lesson_log_count'] / df_wide['normal_lesson_log_count']\n",
    "    df_wide['ask_for_leave_log_percent'] = df_wide['ask_for_leave_log_count'] / df_wide['normal_lesson_log_count']\n",
    "    # 查看上课异常行为的分位数\n",
    "    columns = ['no_show_lesson_log_percent', 'late_lesson_log_percent', \n",
    "               'abnormal_lesson_log_percent', 'ask_for_leave_log_percent', \n",
    "               'abnormal_all_log_percent', 'log_ask_for_leave/log_normal_lesson', \n",
    "               'advanced_days_log_mean', 'advanced_days_max']\n",
    "    quantiles = [0.1, 0.15, 0.2, 0.25, 0.3, 0.33, 0.5, 0.55, 0.6, 0.66, 0.7, 0.75, \n",
    "                 0.77, 0.8, 0.83, 0.85, 0.9, 0.92, 0.95, 1]\n",
    "    for i in range(len(columns)):\n",
    "        print('\\n', columns[i], ':')\n",
    "        for itm in quantiles:\n",
    "            print(str(itm), ':', df_wide.loc[df_wide['normal_lesson_log_count'] > 0, \n",
    "                                                        columns[i]].quantile(itm))\n",
    "    # 老师异常行为有一项出现较大异常值时或整体较差，normal_lesson_log_count降为相应较低数值，整体表现变差\n",
    "    counts = ['ask_for_leave_log_count', 'late_lesson_log_count', \n",
    "               'no_show_lesson_log_count', 'abnormal_lesson_log_count', \n",
    "               'abnormal_all_log_count']\n",
    "    columns = ['ask_for_leave_log_percent', 'late_lesson_log_percent', \n",
    "               'no_show_lesson_log_percent', 'abnormal_lesson_log_percent', \n",
    "               'abnormal_all_log_percent']\n",
    "    cache_columns = ['normal_lesson_log_count_processed_ask_for_leave_cahce1', \n",
    "                     'normal_lesson_log_count_processed_late_lesson_cache2', \n",
    "                     'normal_lesson_log_count_processed_no_show_cache3', \n",
    "                     'normal_lesson_log_count_processed_abnormal_lesson_cache4', \n",
    "                     'normal_lesson_log_count_processed_abnormal_all_cahce5'\n",
    "                    ]\n",
    "    for itm in cache_columns:\n",
    "        df_wide[itm] = df_wide['normal_lesson_log_count']\n",
    "    df_wide['normal_lesson_log_count_processed'] = df_wide['normal_lesson_log_count']\n",
    "    # 分位数\n",
    "    quantiles = [[0.6, 0.7, 0.75, 0.8, 1], [0.8, 0.9, 0.92, 0.95, 1], \n",
    "                [0.5, 0.6, 0.66, 0.75, 0.8, 0.85, 0.9, 1], [0.8, 0.85, 0.9, 0.95, 1], \n",
    "                [0.55, 0.66, 0.75, 0.85, 1]]\n",
    "    # 降低比例\n",
    "    indexes = [[0.8, 0.6, 0.3, 0.1], [0.8, 0.7, 0.3, 0.1], \n",
    "              [0.8, 0.75, 0.6, 0.5, 0.3, 0.1, 0.03], [0.9, 0.85, 0.7, 0.3], \n",
    "              [0.8, 0.7, 0.3, 0.1]]\n",
    "    for i in range(len(columns)):\n",
    "        for k in range(len(quantiles[i]) - 1):\n",
    "            standard1 = df_wide.loc[df_wide['normal_lesson_log_count'] > 0, \n",
    "                                    columns[i]].quantile(quantiles[i][k])\n",
    "            standard2 = df_wide.loc[df_wide['normal_lesson_log_count'] > 0, \n",
    "                                    columns[i]].quantile(quantiles[i][k + 1])\n",
    "            # 降低正常上课的数量\n",
    "            df_wide.loc[(df_wide['normal_lesson_log_count'] > 0) & \n",
    "                (df_wide[columns[i]] > standard1) & (df_wide[columns[i]] <= standard2), \n",
    "                cache_columns[i]] = df_wide['normal_lesson_log_count'] * indexes[i][k]\n",
    "            # 新老师因为平滑原因，所以再复原，不惩罚\n",
    "            df_wide.loc[(df_wide['normal_lesson_log_count'] > 0) & \n",
    "                (df_wide[columns[i]] > standard1) & (df_wide[columns[i]] <= standard2) & \n",
    "                (df_wide[counts[i]] == math.log(2, 10)) & \n",
    "                (df_wide['normal_lesson_log_count'] <= 8), \n",
    "                cache_columns[i]] = df_wide['normal_lesson_log_count']\n",
    "    # 从5行cache_colume中取最小值\n",
    "    df_wide['normal_lesson_log_count_processed'] = df_wide[cache_columns].min(axis=1)\n",
    "    # 大小方向统一化\n",
    "    # 重新计算四个percent\n",
    "    df_wide['late_lesson_log_percent_processed'] = df_wide['late_lesson_log_count'] / df_wide['normal_lesson_log_count_processed']\n",
    "    df_wide['no_show_lesson_log_percent_processed'] = df_wide['no_show_lesson_log_count'] / df_wide['normal_lesson_log_count_processed']\n",
    "    df_wide['abnormal_lesson_log_percent_processed'] = df_wide['abnormal_lesson_log_count'] / df_wide['normal_lesson_log_count_processed']\n",
    "    df_wide['ask_for_leave_log_percent_processed'] = df_wide['ask_for_leave_log_count'] / df_wide['normal_lesson_log_count_processed']\n",
    "    df_wide['normal_log_lesson_per_week'] = df_wide['normal_lesson_log_count_processed'] / (df_wide['lesson_time_range']) \n",
    "    # 取倒数\n",
    "    rcp = ['late_lesson_log_processed', 'no_show_lesson_log_processed', \n",
    "           'abnormal_lesson_log_processed', 'ask_for_leave_log_processed', \n",
    "           'stu_comment_log_bad_behavior_processed']\n",
    "    cols = ['late_lesson_log_percent_processed', 'no_show_lesson_log_percent_processed', \n",
    "            'abnormal_lesson_log_percent_processed', 'ask_for_leave_log_percent_processed', \n",
    "            'stu_comment_log_bad_behavior']\n",
    "    for i in range(len(rcp)):\n",
    "        df_wide[rcp[i]] = 1 / df_wide[cols[i]]\n",
    "    # 修正老师上课数量少但好评较多的情况（如老师id642）\n",
    "    df_wide['stu_comment_log_good_behavior_processed'] = df_wide['stu_comment_log_good_behavior'] / ( \n",
    "                                df_wide['normal_lesson_log_count_all']\n",
    "                                + df_wide['late_lesson_log_count_all'] \n",
    "                                + df_wide['no_show_lesson_log_count_all'] \n",
    "                                + df_wide['ask_for_leave_log_count_all'] \n",
    "                                + df_wide['abnormal_lesson_log_count_all'])                    \n",
    "    df_wide['stu_comment_log_bad_behavior_processed'] = df_wide['stu_comment_log_bad_behavior'] / ( \n",
    "                                df_wide['normal_lesson_log_count_all'])\n",
    "    # 修正老师请假次数过多，但提前请假天数指标过好的情况（如老师id642） \n",
    "    columns = ['advanced_days_log_mean', 'advanced_days_max']\n",
    "    quantiles = [0.6, 0.66, 0.7, 0.75, 0.77, 0.8, 0.85, 1]\n",
    "    indexes = [0.9, 0.8, 0.7, 0.5, 0.3, 0.1, 0.05]\n",
    "    for i in range(len(columns)):\n",
    "        for k in range(len(quantiles) - 1):\n",
    "            percent1 = df_wide.loc[df_wide['normal_lesson_log_count'] > 0, \n",
    "                                'log_ask_for_leave/log_normal_lesson'].quantile(quantiles[k])\n",
    "            percent2 = df_wide.loc[df_wide['normal_lesson_log_count'] > 0, \n",
    "                                'log_ask_for_leave/log_normal_lesson'].quantile(quantiles[k + 1])\n",
    "            df_wide.loc[(df_wide['normal_lesson_log_count'] > 0) & \n",
    "                        (df_wide['log_ask_for_leave/log_normal_lesson'] > percent1) & \n",
    "                        (df_wide['log_ask_for_leave/log_normal_lesson'] <= percent2), \n",
    "                        columns[i]] = df_wide[columns[i]] * indexes[k]\n",
    "    # 无上课记录老师\n",
    "    columns = list(df_wide.columns)\n",
    "    columns.pop(columns.index('awj_teacher_id'))\n",
    "    for itm in columns:\n",
    "        df_wide.loc[df_wide['normal_lesson_log_count'] == 0, itm] = 0\n",
    "    # 只取有行为数据的\n",
    "    df_wide_final = df_wide.loc[df_wide['normal_lesson_log_count'] > 0]\n",
    "    # delete columns\n",
    "    df_wide_final.drop(['advanced_days_std', 'teacher_score_std', \n",
    "                  'advanced_days_min', 'lesson_time_range', \n",
    "                  'normal_lesson_log_count_all', 'no_show_lesson_log_count_all', \n",
    "                  'abnormal_lesson_log_count_all', 'late_lesson_log_count_all', \n",
    "                  'ask_for_leave_log_count_all', 'old_new_teacher', \n",
    "                  'teacher_qc_count', 'normal_lesson_log_count', 'late_lesson_log_count', \n",
    "                  'no_show_lesson_log_count', 'abnormal_lesson_log_count', \n",
    "                  'ask_for_leave_log_count', 'stu_comment_log_good_behavior', \n",
    "                  'stu_comment_log_bad_behavior', \n",
    "                  'log_ask_for_leave/log_normal_lesson',  'abnormal_lesson_log_percent',\n",
    "                  'late_lesson_log_percent', 'no_show_lesson_log_percent', \n",
    "                  'ask_for_leave_log_percent', 'abnormal_all_log_count', \n",
    "                  'late_lesson_log_percent_processed', 'no_show_lesson_log_percent_processed', \n",
    "                  'abnormal_lesson_log_percent_processed', 'ask_for_leave_log_percent_processed', \n",
    "                  'normal_lesson_log_count_processed', 'abnormal_all_log_percent', \n",
    "                  'normal_lesson_log_count_processed_ask_for_leave_cahce1', \n",
    "                  'normal_lesson_log_count_processed_late_lesson_cache2', \n",
    "                  'normal_lesson_log_count_processed_no_show_cache3', \n",
    "                  'normal_lesson_log_count_processed_abnormal_lesson_cache4', \n",
    "                  'normal_lesson_log_count_processed_abnormal_all_cahce5',                                        \n",
    "                  'normal_log_lesson_per_week', \n",
    "                  'stu_comment_log_bad_behavior_processed'], \n",
    "                   axis=1, inplace=True)\n",
    "    # save\n",
    "    df_wide_final.to_csv(path + 'df_wide_log_final.csv', sep=',', float_format='%.5f', \n",
    "                         index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1386,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fa_index1</th>\n",
       "      <th>fa_index2</th>\n",
       "      <th>fa_index3</th>\n",
       "      <th>fa_index4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.067965</td>\n",
       "      <td>0.007287</td>\n",
       "      <td>0.535777</td>\n",
       "      <td>0.057239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.081179</td>\n",
       "      <td>0.007034</td>\n",
       "      <td>0.541467</td>\n",
       "      <td>0.043481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.021609</td>\n",
       "      <td>0.338660</td>\n",
       "      <td>0.003847</td>\n",
       "      <td>-0.008771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.046738</td>\n",
       "      <td>0.344282</td>\n",
       "      <td>0.012750</td>\n",
       "      <td>-0.010007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.035079</td>\n",
       "      <td>0.348230</td>\n",
       "      <td>0.003747</td>\n",
       "      <td>-0.018199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.283483</td>\n",
       "      <td>-0.024297</td>\n",
       "      <td>-0.030890</td>\n",
       "      <td>-0.024959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.318853</td>\n",
       "      <td>-0.032983</td>\n",
       "      <td>-0.056064</td>\n",
       "      <td>0.024066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.307936</td>\n",
       "      <td>-0.026679</td>\n",
       "      <td>-0.050784</td>\n",
       "      <td>0.083130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.293590</td>\n",
       "      <td>-0.038004</td>\n",
       "      <td>-0.083815</td>\n",
       "      <td>-0.077168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.002655</td>\n",
       "      <td>-0.017316</td>\n",
       "      <td>0.062766</td>\n",
       "      <td>1.001195</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fa_index1  fa_index2  fa_index3  fa_index4\n",
       "0  -0.067965   0.007287   0.535777   0.057239\n",
       "1  -0.081179   0.007034   0.541467   0.043481\n",
       "2  -0.021609   0.338660   0.003847  -0.008771\n",
       "3  -0.046738   0.344282   0.012750  -0.010007\n",
       "4  -0.035079   0.348230   0.003747  -0.018199\n",
       "5   0.283483  -0.024297  -0.030890  -0.024959\n",
       "6   0.318853  -0.032983  -0.056064   0.024066\n",
       "7   0.307936  -0.026679  -0.050784   0.083130\n",
       "8   0.293590  -0.038004  -0.083815  -0.077168\n",
       "9   0.002655  -0.017316   0.062766   1.001195"
      ]
     },
     "execution_count": 1386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FA_indexs\n",
    "fa_index = pd.read_excel(path + 'fa_indexs.xlsx')\n",
    "fa_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1387,
   "metadata": {},
   "outputs": [],
   "source": [
    "fa_index = fa_index.as_matrix()\n",
    "df_wide_matrix = deepcopy(df_wide_final)\n",
    "df_wide_matrix.drop(['awj_teacher_id'], axis=1, inplace=True)\n",
    "df_wide_matrix = df_wide_matrix.as_matrix()\n",
    "# df_wide标准化\n",
    "df_wide_matrix = preprocessing.scale(df_wide_matrix)\n",
    "# 每个老师的各因子得分\n",
    "fa_score = np.dot(df_wide_matrix, fa_index)\n",
    "# 主成分贡献率\n",
    "var = np.array([[0.37591 / 0.88651], \n",
    "                [0.26337 / 0.88651], \n",
    "                [0.15250 / 0.88651], \n",
    "                [0.09473 / 0.88651]])\n",
    "# 每个老师的最终得分\n",
    "final_score = np.dot(fa_score, var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1388,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.64510173,  0.64221538, -2.8563948 , ..., -0.80794209,\n",
       "        -0.50703312,  0.68070896],\n",
       "       [ 0.64510173,  0.64221538,  0.77096003, ..., -0.0284943 ,\n",
       "         0.29034945,  1.45984841],\n",
       "       [ 1.18135717,  1.32438571,  0.3254954 , ...,  1.50877572,\n",
       "        -0.36389545,  0.3387012 ],\n",
       "       ..., \n",
       "       [-1.01376301, -1.09700942,  0.34443014, ..., -0.28994887,\n",
       "        -0.48274743,  1.93341094],\n",
       "       [-1.01376301, -1.09700942,  0.34443014, ..., -0.28994887,\n",
       "        -0.48274743,  1.93341094],\n",
       "       [-1.01376301, -1.09700942,  0.34443014, ..., -0.28994887,\n",
       "        -0.48274743,  1.93341094]])"
      ]
     },
     "execution_count": 1388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_wide_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1389,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5: 0.4300128351995921 4: -0.03284055912807754 3: -0.34222457378724547 2: -0.8124805247179571\n"
     ]
    }
   ],
   "source": [
    "# df格式\n",
    "teacher_fa_score = np.hstack((fa_score, final_score))\n",
    "teacher_fa_score = pd.DataFrame(teacher_fa_score)\n",
    "teacher_fa_score['awj_teacher_id'] = list(df_wide_final['awj_teacher_id'])\n",
    "teacher_fa_score.rename(columns={0: 'teacher_behavior_score', 1: 'teacher_qc_score', \n",
    "                                 2:'teacher_attitude_score', 3: 'student_comment_good_score', \n",
    "                                 4: 'final_score'}, inplace=True)\n",
    "# 星级映射(去除过去一段时间周期内没上过课的老师)\n",
    "teacher_fa_score = teacher_fa_score.sort_values(by='final_score', ascending=0)\n",
    "# 业务要求的分位数\n",
    "star_5 = teacher_fa_score['final_score'].quantile(0.8)\n",
    "star_4 = teacher_fa_score['final_score'].quantile(0.5)\n",
    "star_3 = teacher_fa_score['final_score'].quantile(0.2)\n",
    "star_2 = teacher_fa_score['final_score'].quantile(0.1)\n",
    "print('5:', star_5, '4:', star_4, '3:', star_3, '2:', star_2)\n",
    "teacher_fa_score.loc[teacher_fa_score['final_score'] <= star_2, 'star'] = 1\n",
    "teacher_fa_score.loc[(teacher_fa_score['final_score'] > star_2) & \n",
    "                     (teacher_fa_score['final_score'] <= star_3), 'star'] = 2\n",
    "teacher_fa_score.loc[(teacher_fa_score['final_score'] > star_3) & \n",
    "                     (teacher_fa_score['final_score'] <= star_4), 'star'] = 3\n",
    "teacher_fa_score.loc[(teacher_fa_score['final_score'] > star_4) & \n",
    "                     (teacher_fa_score['final_score'] <= star_5), 'star'] = 4\n",
    "teacher_fa_score.loc[teacher_fa_score['final_score'] > star_5, 'star'] = 5\n",
    "# 拼回去\n",
    "teacher_fa_score = pd.merge(teacher_fa_score, df_wide[\n",
    "    ['awj_teacher_id', 'normal_lesson_log_count']], on='awj_teacher_id', how='right')\n",
    "teacher_fa_score.fillna(value=0, inplace=True)\n",
    "# 没上过课的老老师都统一补为3星\n",
    "teacher_fa_score['star'] = teacher_fa_score['star'].replace({0: 3})\n",
    "teacher_fa_score.to_csv(path + 'teacher_star.csv', sep=',', float_format='%.5f', \n",
    "                        encoding='utf-8', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
