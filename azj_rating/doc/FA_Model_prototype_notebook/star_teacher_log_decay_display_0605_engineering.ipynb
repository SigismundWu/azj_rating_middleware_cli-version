{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas.tseries.offsets import *\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import math\n",
    "from copy import deepcopy\n",
    "import json\n",
    "from itertools import combinations, permutations\n",
    "import warnings\n",
    "\n",
    "% matplotlib inline\n",
    "pd.set_option('max_columns', 100)\n",
    "pd.set_option('max_rows', 500)\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 以这个list pick出需要的东西\n",
    "# 分层抽样，实际结果的5到0星的教师都有，随机抽取\n",
    "# 0分的只取一个\n",
    "pick_list = [871, 279, 1271, 191, 1907, 556, 1569, 624, 741, 1826, 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 这里读取几张原表，pick上面的list里面需要的参数，然后对老师的id进行修改，隐藏相关信息\n",
    "# 审查学生评论的部分\n",
    "# 教师id改成int，然后sort，然后顺序替换，确保数据对得上\n",
    "path = './FA_Model_data/'\n",
    "df_teacher_monitoring = pd.read_csv(path + 'awj_teacher_monitoring.csv', encoding='utf-8', sep=',')\n",
    "df_qc = pd.read_csv(path + '老师qc明细.csv', encoding='utf-8', sep=',')\n",
    "df_teacher_behavior = pd.read_csv(path + '老师行为信息明细.csv', sep=',', encoding='utf-8')\n",
    "df_teacher_info = pd.read_csv(path + '老师基本信息.csv', sep=',', encoding='utf-8')\n",
    "df_stu_comment = pd.read_csv(path + '学生评价明细.csv', sep=',', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学生的comment（唯一会暴露教师姓名个人信息的部分，完全可以不要，到时候drop掉这个comment列）\n",
    "df_teacher_monitoring = df_teacher_monitoring[df_teacher_monitoring.awj_teacher_id.isin(pick_list)]\n",
    "df_teacher_monitoring.drop(\"comment\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 评论，这张表唯一一个会暴露教师信息的地方，也根本没被用到过，因此这个也是可以不被需要的\n",
    "# 机构那一列全部改成一个统一的字符串就行：例如：community\n",
    "df_stu_comment = df_stu_comment[df_stu_comment.awj_teacher_id.isin(pick_list)]\n",
    "df_stu_comment.drop(\"评论\", axis=1, inplace=True)\n",
    "df_stu_comment.drop(\"标签内容\", axis=1, inplace=True)\n",
    "df_stu_comment[\"机构\"] = \"com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "# qc分数\n",
    "# 有很多没用的列，全部drop，节省空间\n",
    "df_qc = df_qc[df_qc.awj_teacher_id.isin(pick_list)]\n",
    "df_qc.drop(\"teacher_name\", axis=1, inplace=True)\n",
    "df_qc.drop(\"notes\", axis=1, inplace=True)\n",
    "df_qc.drop(\"qcer\", axis=1, inplace=True)\n",
    "df_qc.drop(\"course_name\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "# teacher_behavior\n",
    "# 机构那一列全部改成一个统一的字符串就行：例如：community\n",
    "df_teacher_behavior = df_teacher_behavior[df_teacher_behavior.awj_teacher_id.isin(pick_list)]\n",
    "df_teacher_behavior.drop(\"教材\", axis=1, inplace=True)\n",
    "df_teacher_behavior[\"机构\"] = \"com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "# teacher_info\n",
    "df_teacher_info = df_teacher_info[df_teacher_info.awj_teacher_id.isin(pick_list)]\n",
    "df_teacher_info.drop([\"country\", \"timezone\", \"degree_and_university\", \"child_exp\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 下面就是伪造测试数据的部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 函数已经测试通过\n",
    "# 把teacher_id按照pick_list里面的顺序分别分配0到10的假代号给他们\n",
    "def process_teacher_id(pick_list, df):\n",
    "    n = 0\n",
    "    df_processed = pd.DataFrame()\n",
    "    for i in pick_list:\n",
    "        df_tmp = df[df[\"awj_teacher_id\"] == i]\n",
    "        df_tmp[\"awj_teacher_id\"] = n\n",
    "        df_processed = pd.concat([df_processed, df_tmp])\n",
    "        n += 1\n",
    "    return df_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 把所有的id整理好\n",
    "df_teacher_monitoring = process_teacher_id(pick_list, df_teacher_monitoring)\n",
    "df_qc = process_teacher_id(pick_list, df_qc)\n",
    "df_teacher_behavior = process_teacher_id(pick_list, df_teacher_behavior)\n",
    "df_teacher_info = process_teacher_id(pick_list, df_teacher_info)\n",
    "df_stu_comment = process_teacher_id(pick_list, df_stu_comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 整理一下index\n",
    "df_teacher_monitoring.reset_index(drop=True, inplace=True)\n",
    "df_qc.reset_index(drop=True, inplace=True)\n",
    "df_teacher_behavior.reset_index(drop=True, inplace=True)\n",
    "df_teacher_info.reset_index(drop=True, inplace=True)\n",
    "df_stu_comment.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 教师的编号伪装完成，需要的已经全部去掉"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_path = \"./FA_Model_test/\"\n",
    "df_teacher_monitoring.to_csv(t_path + 'awj_teacher_monitoring.csv', encoding='utf-8', sep=',', index=False)\n",
    "df_qc.to_csv(t_path + '老师qc明细.csv', encoding='utf-8', sep=',', index=False)\n",
    "df_teacher_behavior.to_csv(t_path + '老师行为信息明细.csv', sep=',', encoding='utf-8', index=False)\n",
    "df_teacher_info.to_csv(t_path + '老师基本信息.csv', sep=',', encoding='utf-8', index=False)\n",
    "df_stu_comment.to_csv(t_path + '学生评价明细.csv', sep=',', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "def teacher_qc_score(start_time, end_time, df_qc, class_type_name_special, hq_name_special):\n",
    "    # 筛选条件\n",
    "    df_qc = df_qc.loc[(~df_qc['class_type_name'].isin(class_type_name_special)) & \n",
    "                    (~df_qc['hq_name'].isin(hq_name_special)) & \n",
    "                    (df_qc['start_time'] >= start_time) & (df_qc['end_time'] <= end_time)]\n",
    "    # log score-mean\n",
    "    df_qc['decay_index'] = ((end_time - df_qc['score_recorded_at']).dt.total_seconds()) / (3600 * 24) \n",
    "    df_qc.loc[df_qc['decay_index'] < 0, 'decay_index'] = 0 # qc时间有时会在end_time之后造成负值\n",
    "    df_qc['decay_index'] = df_qc['decay_index'] + 2 # log计算，防止0值+1;取倒数+1，防止无穷情况\n",
    "    df_qc['decay_index'] = df_qc['decay_index'].apply(lambda x: math.log(x, 10))\n",
    "    df_qc['decay_index'] = 1 / df_qc['decay_index']\n",
    "    df_qc['log_decay_score'] = df_qc['score'] * df_qc['decay_index']\n",
    "    df_teacher_log_score = df_qc.groupby(['awj_teacher_id'], \n",
    "                        as_index=False).agg({'log_decay_score': np.sum, 'decay_index': np.sum})\n",
    "    df_teacher_log_score['log_decay_score_mean'] = df_teacher_log_score['log_decay_score'] / df_teacher_log_score['decay_index']\n",
    "    df_teacher_log_score = df_teacher_log_score[['awj_teacher_id', 'log_decay_score_mean']]\n",
    "    # score\n",
    "    df_teacher_score = df_qc.groupby(['awj_teacher_id'], \n",
    "                as_index=False)['score'].agg(['max', 'min', 'count', np.std]) \n",
    "    # std missing\n",
    "    df_teacher_score.loc[df_teacher_score['std'].isnull(), 'std'] = df_teacher_score['std'].mean()\n",
    "    df_teacher_score.rename(columns={'max': 'teacher_score_max', 'min': 'teacher_score_min', \n",
    "                        'count': 'teacher_qc_count', 'std': 'teacher_score_std'}, inplace=True)\n",
    "    df_teacher_score.reset_index(inplace=True)\n",
    "    # merge\n",
    "    df_qc_res = pd.merge(df_teacher_score, df_teacher_log_score, on='awj_teacher_id', how='left')\n",
    "    return df_qc_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "def teacher_behavior(start_time, end_time, df_teacher_behavior, \n",
    "                                class_type_name_special, hq_name_special):\n",
    "    # 筛选条件\n",
    "    df_teacher_behavior = df_teacher_behavior.loc[\n",
    "                    (~df_teacher_behavior['上课类型'].isin(class_type_name_special)) & \n",
    "                    (~df_teacher_behavior['机构'].isin(hq_name_special)) & \n",
    "                    (df_teacher_behavior['start_time'] >= start_time) & \n",
    "                    (df_teacher_behavior['end_time'] <= end_time) & \n",
    "                    (~df_teacher_behavior['teacher_status_for_lesson'].isin(['system_failure']))]\n",
    "    # 预处理\n",
    "    df_teacher_behavior['lesson_count'] = ((df_teacher_behavior['end_time'] - \n",
    "                        df_teacher_behavior['start_time']).dt.total_seconds()) / 3600 * 2\n",
    "    df_teacher_behavior.loc[df_teacher_behavior['teacher_status_for_lesson'] == 'no_show', \n",
    "                            'ask_for_leave_advanced_minutes'] = 0\n",
    "    df_teacher_behavior['ask_for_leave_advanced_days'] = df_teacher_behavior['ask_for_leave_advanced_minutes'] / (60 * 24)\n",
    "    # 天数衰减\n",
    "    df_teacher_behavior['decay_index'] = ((end_time - \n",
    "            df_teacher_behavior['start_time']).dt.total_seconds()) / (3600 * 24) \n",
    "    df_teacher_behavior.loc[df_teacher_behavior['decay_index'] < 0, 'decay_index'] = 0\n",
    "    # log计算，防止0值+1;取倒数+1，防止无穷情况\n",
    "    df_teacher_behavior['decay_index'] = df_teacher_behavior['decay_index'] + 2\n",
    "    df_teacher_behavior['decay_index'] = df_teacher_behavior['decay_index'].apply(lambda x: math.log(x, 10))\n",
    "    df_teacher_behavior['decay_index'] = 1 / df_teacher_behavior['decay_index']\n",
    "    # count lesson types\n",
    "    df_teacher_behavior_res = df_teacher_behavior[['awj_teacher_id']]\n",
    "    df_teacher_behavior_res.drop_duplicates(keep='first', inplace=True)\n",
    "    types = ['normal_lesson', 'late', 'no_show', 'abnormal_lesson', 'ask_for_leave']\n",
    "    for itm in types:\n",
    "        df_count = df_teacher_behavior.loc[\n",
    "            df_teacher_behavior['teacher_status_for_lesson'].isin([itm])]\n",
    "        df_count['log_lesson_count'] = df_count['lesson_count'] * df_count['decay_index']\n",
    "        df_count = df_count.groupby(['awj_teacher_id'], as_index=False)['log_lesson_count'].sum()\n",
    "        df_count.reset_index()\n",
    "        if (itm.find('ask_for_leave') > -1) | (itm.find('lesson') > -1):\n",
    "            df_count.rename(columns={'log_lesson_count': itm + '_log_count'}, inplace=True)\n",
    "        else:\n",
    "            df_count.rename(columns={'log_lesson_count': itm + '_lesson_log_count'}, inplace=True)\n",
    "        df_teacher_behavior_res = pd.merge(df_teacher_behavior_res, df_count, \n",
    "                                                  on='awj_teacher_id', how='left')\n",
    "    # ask for leave advanced minutes\n",
    "    df_advanced_days = df_teacher_behavior.loc[\n",
    "        df_teacher_behavior['teacher_status_for_lesson'].isin(['ask_for_leave', 'no_show'])]  \n",
    "    df_advanced_days['ask_for_leave_advanced_log_days'] = df_advanced_days['decay_index'] * df_advanced_days['ask_for_leave_advanced_days']\n",
    "    # 求均值\n",
    "    df_advanced_days_mean = df_advanced_days.groupby(['awj_teacher_id'], as_index=False).agg(\n",
    "        {'ask_for_leave_advanced_log_days': np.sum, 'decay_index': np.sum})\n",
    "    df_advanced_days_mean.reset_index(inplace=True)\n",
    "    df_advanced_days_mean['advanced_days_log_mean'] = df_advanced_days_mean['ask_for_leave_advanced_log_days'] / df_advanced_days_mean['decay_index'] \n",
    "    df_advanced_days_mean = df_advanced_days_mean[['awj_teacher_id', 'advanced_days_log_mean']]\n",
    "    # 求最大最小值及方差\n",
    "    df_advanced_days_others = df_advanced_days.groupby(['awj_teacher_id'], \n",
    "            as_index=False)['ask_for_leave_advanced_days'].agg(['min', 'max', 'std'])\n",
    "    df_advanced_days_others.reset_index(inplace=True)\n",
    "    df_advanced_days_others.loc[df_advanced_days_others['std'].isnull(), \n",
    "                                'std'] = df_advanced_days_others['std'].mean()\n",
    "    df_advanced_days_others.rename(columns={'min': 'advanced_days_min', \n",
    "                    'max': 'advanced_days_max', 'std': 'advanced_days_std'}, inplace=True)\n",
    "    df_advanced_days = pd.merge(df_advanced_days_mean, df_advanced_days_others, \n",
    "                               on='awj_teacher_id', how='left')\n",
    "    df_teacher_behavior_res = pd.merge(df_teacher_behavior_res, df_advanced_days, \n",
    "                                                       on='awj_teacher_id', how='left')\n",
    "    # fill 0\n",
    "    columns = ['normal_lesson_log_count', 'late_lesson_log_count', 'no_show_lesson_log_count', \n",
    "               'abnormal_lesson_log_count', 'ask_for_leave_log_count', 'advanced_days_log_mean', \n",
    "               'advanced_days_min', 'advanced_days_max', 'advanced_days_std']\n",
    "    for itm in columns:\n",
    "        df_teacher_behavior_res[itm].fillna(value=0, inplace=True)\n",
    "    return df_teacher_behavior_res, df_teacher_behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stu_comment(start_time, end_time, df_stu_comment, \n",
    "                class_type_name_special, hq_name_special, df_teacher_behavior_processed_cache):\n",
    "    # 筛选条件：时间筛选条件由于筛选后数量过少，所以采用end time前的全量数据\n",
    "    df_stu_comment = df_stu_comment.loc[(df_stu_comment['课程开始时间'] >= start_time) & \n",
    "                                (df_stu_comment['课程结束时间'] <= end_time) & \n",
    "                                (~df_stu_comment['机构'].isin(hq_name_special)) & \n",
    "                                (~df_stu_comment['课程类型'].isin(class_type_name_special))]\n",
    "    print('df_stu_comment_floater classes existed:', df_stu_comment.shape)\n",
    "    # 与行为表对比，去除floater课程\n",
    "    df_stu_comment = pd.merge(df_stu_comment, df_teacher_behavior_processed_cache, \n",
    "                             left_on=['awj_teacher_id', 'awjcls_lesson_id'], \n",
    "                             right_on=['awj_teacher_id', 'awj_lesson_id'], how='left')\n",
    "    df_stu_comment = df_stu_comment.loc[~df_stu_comment['is_deleted'].isnull()]\n",
    "    df_stu_comment.drop(['awj_lesson_id', 'is_deleted'], axis=1, inplace=True)\n",
    "    print('df_stu_comment_floater classes deleted:', df_stu_comment.shape)\n",
    "    # 天数衰减\n",
    "    df_stu_comment['decay_index'] = ((end_time - \n",
    "            df_stu_comment['评价时间']).dt.total_seconds()) / (3600 * 24) \n",
    "    df_stu_comment.loc[df_stu_comment['decay_index'] < 0, 'decay_index'] = 0\n",
    "    # log计算，防止0值+1;取倒数+1，防止无穷情况\n",
    "    df_stu_comment['decay_index'] = df_stu_comment['decay_index'] + 2\n",
    "    df_stu_comment['decay_index'] = df_stu_comment['decay_index'].apply(lambda x: math.log(x, 10))\n",
    "    df_stu_comment['decay_index'] = 1 / df_stu_comment['decay_index']  \n",
    "    # 4，5星统计(4，5星负面标签都是系统bug)\n",
    "    df_good_label = df_stu_comment.loc[df_stu_comment['学生评价星级'].isin(['5-star', '4-star'])]\n",
    "    df_good_label['lesson_count_processed'] = df_good_label['lesson_count'] * df_good_label['decay_index']\n",
    "    df_good_label = df_good_label.groupby(['awj_teacher_id'], \n",
    "                            as_index=False)['lesson_count_processed'].sum()\n",
    "    df_good_label.rename(columns={'lesson_count_processed': 'stu_comment_log_good_behavior'}, inplace=True)\n",
    "    # 1~3星统计\n",
    "    df_bad_label = df_stu_comment.loc[~df_stu_comment['学生评价星级'].isin(['5-star', '4-star'])]\n",
    "    df_bad_label['lesson_count_processed'] = df_bad_label['lesson_count'] * df_bad_label['decay_index']\n",
    "    df_bad_label = df_bad_label.groupby(['awj_teacher_id'], \n",
    "                                as_index=False)['lesson_count_processed'].sum()\n",
    "    df_bad_label.rename(columns={'lesson_count_processed': 'stu_comment_log_bad_behavior'}, inplace=True)\n",
    "    # merge\n",
    "    df_stu_comment_res = pd.merge(df_good_label, df_bad_label, on='awj_teacher_id', how='outer')\n",
    "    df_stu_comment_res['stu_comment_log_bad_behavior'].fillna(value=0, inplace=True)\n",
    "    df_stu_comment_res['stu_comment_log_good_behavior'].fillna(value=0, inplace=True)\n",
    "    return df_stu_comment_res, df_stu_comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start_time: 2018-01-30 23:59:59 \n",
      " end_time: 2018-04-30 23:59:59 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#     end_time = pd.to_datetime(datetime.datetime.now().date()) + MonthEnd(n=-1) + DateOffset(hours=23.99999)\n",
    "#     start_time = end_time - DateOffset(months=3)\n",
    "end_time = datetime.datetime(2018, 4, 30, 23, 59, 59)\n",
    "start_time = datetime.datetime(2018, 1, 30, 23, 59, 59)\n",
    "class_type_name_special = ['Demo', '补课(非爱乐奇直属老师)', '托福班（30刀）', 'TOFEL', \n",
    "                          'VIP Writing/TOFEL（35刀）', 'Elite Pilot', 'Feeback Session', \n",
    "                          'New Teacher Test Class', '补课(爱乐奇直属老师)', 'Test Class', \n",
    "                          'Academic Meeting (Long)', 'Cur Experience Session-S', \n",
    "                          'Training-receiving', 'Cur Experience Session-L', \n",
    "                          'VIP Writing/TOFEL', 'Orientation Class', 'Academic Meeting', \n",
    "                          'Experience-receiving']\n",
    "hq_name_special = ['test']\n",
    "print('start_time:', start_time, '\\n', 'end_time:', end_time, '\\n')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##### 老师监控表 #####\n",
    "# dtypes\n",
    "df_teacher_monitoring['awj_teacher_id'] = df_teacher_monitoring['awj_teacher_id'].astype('int')\n",
    "df_teacher_monitoring['created_at'] = pd.to_datetime(df_teacher_monitoring['created_at'])\n",
    "# drop duplicates\n",
    "df_teacher_monitoring.drop_duplicates(\n",
    "                    subset=list(df_teacher_monitoring.columns), keep='first', inplace=True)\n",
    "# sort\n",
    "df_teacher_monitoring = df_teacher_monitoring.sort_values(\n",
    "                by=['awj_teacher_id', 'awjcls_lesson_id', 'created_at'], ascending=[1, 1, 1])\n",
    "# 该表只取abnormal_type为4，5的行，分别表示zoom崩溃和课件崩溃，非老师原因\n",
    "df_teacher_monitoring = df_teacher_monitoring.loc[\n",
    "                df_teacher_monitoring['abnormal_type'].isin([4, 5])]\n",
    "df_teacher_monitoring = df_teacher_monitoring.groupby(\n",
    "            ['awj_teacher_id', 'awjcls_lesson_id', 'abnormal_type'], as_index=False).last()\n",
    "\n",
    "\n",
    "#     df_teacher_monitoring.to_csv(\"教师监控_res.csv\", index=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##### 老师QC明细表 #####\n",
    "# dtypes\n",
    "df_qc['awj_teacher_id'] = df_qc['awj_teacher_id'].astype('int')\n",
    "df_qc['score_recorded_at'] = pd.to_datetime(df_qc['score_recorded_at'])\n",
    "df_qc['assigned_at'] = pd.to_datetime(df_qc['assigned_at'])\n",
    "df_qc['start_time'] = pd.to_datetime(df_qc['start_time'])\n",
    "df_qc['end_time'] = pd.to_datetime(df_qc['end_time'])\n",
    "# drop duplicates-老师同一堂课有时会有多次qc，check后发现分数都一样，所以去重时按照以下字段去重即可\n",
    "columns = ['awj_teacher_id', 'awjcls_lesson_id', 'score']\n",
    "df_qc.drop_duplicates(subset=columns, keep='last', inplace=True)\n",
    "# sort\n",
    "df_qc = df_qc.sort_values(by=['awj_teacher_id', 'start_time'], ascending=[1, 1])\n",
    "\n",
    "#     df_qc.to_csv(\"教师qc_res.csv\", index=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##### 老师行为表 #####\n",
    "# dtypes\n",
    "df_teacher_behavior['awj_teacher_id'] = df_teacher_behavior['awj_teacher_id'].astype('int')\n",
    "df_teacher_behavior['start_time'] = pd.to_datetime(df_teacher_behavior['start_time'])\n",
    "df_teacher_behavior['end_time'] = pd.to_datetime(df_teacher_behavior['end_time'])\n",
    "df_teacher_behavior['actual_start_time'] = pd.to_datetime(df_teacher_behavior['actual_start_time'])\n",
    "df_teacher_behavior['actual_end_time'] = pd.to_datetime(df_teacher_behavior['actual_end_time'])\n",
    "df_teacher_behavior.drop_duplicates(subset=list(df_teacher_behavior.columns), inplace=True)\n",
    "# sort\n",
    "# 原本这里是“积分变化”，sort的最后一个字段，改成了teacher_status_for_lesson\n",
    "df_teacher_behavior = df_teacher_behavior.sort_values(by=[\n",
    "        'awj_teacher_id', 'awj_lesson_id', 'start_time', 'teacher_status_for_lesson'], ascending=[1, 1, 1, 1])\n",
    "# 老师id加lesson_id应该唯一，但有时有重复情况，因为有些老师先请了假，后来又来上课了，所以请假应该去除\n",
    "df_teacher_behavior = df_teacher_behavior.groupby(\n",
    "            ['awj_teacher_id', 'awj_lesson_id'], as_index=False).last()\n",
    "# 与monitoring表对比，去除老师abnormal_lesson细分为4，5状态下的课程记录\n",
    "df_teacher_behavior = pd.merge(df_teacher_behavior, \n",
    "                df_teacher_monitoring[['awj_teacher_id', 'awjcls_lesson_id', 'abnormal_type']], \n",
    "                left_on=['awj_teacher_id', 'awj_lesson_id'], \n",
    "                right_on=['awj_teacher_id', 'awjcls_lesson_id'], how='left')\n",
    "index = df_teacher_behavior.loc[\n",
    "                (df_teacher_behavior['teacher_status_for_lesson'] == 'abnormal_lesson') & \n",
    "                (df_teacher_behavior['abnormal_type'].isin([4, 5]))].index\n",
    "df_teacher_behavior = df_teacher_behavior.loc[~df_teacher_behavior.index.isin(list(index))]\n",
    "df_teacher_behavior.drop(['awjcls_lesson_id', 'abnormal_type'], axis=1, inplace=True)\n",
    "\n",
    "#     df_teacher_behavior.to_csv(\"教师行为_res.csv\", index=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##### 老师信息表 #####\n",
    "# dtypes\n",
    "df_teacher_info['awj_teacher_id'] = df_teacher_info['awj_teacher_id'].astype(int)\n",
    "df_teacher_info['创建时间'] = pd.to_datetime(df_teacher_info['创建时间'])\n",
    "df_teacher_info['首次上架时间'] = pd.to_datetime(df_teacher_info['首次上架时间'])\n",
    "df_teacher_info['首课时间'] = pd.to_datetime(df_teacher_info['首课时间'])\n",
    "df_teacher_info.drop_duplicates(\n",
    "    subset=list(df_teacher_info.columns), keep='first', inplace=True)\n",
    "# 根据业务要求只取某些type类型老师，其他去除\n",
    "df_teacher_info = df_teacher_info.loc[df_teacher_info['teacher_type'].isin([\n",
    "            'booking&arrangement', 'arrangement_only', 'booking_only'])]\n",
    "# sort\n",
    "df_teacher_info = df_teacher_info.sort_values(by=['awj_teacher_id'], ascending=[1])\n",
    "df_teacher_info = df_teacher_info[['awj_teacher_id', 'state', '创建时间', \n",
    "                                                       '首次上架时间', '首课时间']]\n",
    "\n",
    "\n",
    "#     df_teacher_info.to_csv(\"教师信息_res.csv\", index=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##### 学生评价明细表 #####\n",
    "# dtypes\n",
    "df_stu_comment['awj_teacher_id'] = df_stu_comment['awj_teacher_id'].astype(int)\n",
    "df_stu_comment['学生评价星级'] = df_stu_comment['学生评价星级'].astype('str')\n",
    "df_stu_comment = df_stu_comment.loc[df_stu_comment['学生评价星级'].isin(['1-star', '2-star', \n",
    "                                                        '3-star', '4-star', '5-star'])]\n",
    "df_stu_comment['评价时间'] = pd.to_datetime(df_stu_comment['评价时间'])\n",
    "df_stu_comment['课程开始时间'] = pd.to_datetime(df_stu_comment['课程开始时间'])\n",
    "df_stu_comment['课程结束时间'] = pd.to_datetime(df_stu_comment['课程结束时间'])\n",
    "df_stu_comment.drop_duplicates(subset=list(df_stu_comment.columns), keep='first', inplace=True)\n",
    "# sort\n",
    "df_stu_comment = df_stu_comment.sort_values(by=[\n",
    "                        'awj_teacher_id', '评价时间'], ascending=[1, 1]) \n",
    "#     # 老师一次上两堂课，好评不应只算作1次\n",
    "#     df_stu_comment['lesson_count'] = ((df_stu_comment['课程结束时间'] - \n",
    "#                               df_stu_comment['课程开始时间']).dt.total_seconds()) / 3600 * 2\n",
    "# 此处仍然算一次，两次效果非常差\n",
    "df_stu_comment['lesson_count'] = 1\n",
    "df_stu_comment = df_stu_comment.groupby(['评价id'], as_index=False).last()\n",
    "\n",
    "#     df_stu_comment.to_csv(\"学生评价_res.csv\", index=False)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_stu_comment_floater classes existed: (759, 11)\n",
      "df_stu_comment_floater classes deleted: (759, 11)\n"
     ]
    }
   ],
   "source": [
    "# 函数调用\n",
    "df_qc_res = teacher_qc_score(start_time, end_time, df_qc, \n",
    "                             class_type_name_special, hq_name_special)\n",
    "\n",
    "#     df_qc_res.to_csv(\"df_qc_res.csv\", index=False)\n",
    "\n",
    "\n",
    "df_teacher_behavior_res, df_teacher_behavior_processed = teacher_behavior(\n",
    "                    start_time, end_time, df_teacher_behavior, \n",
    "                    class_type_name_special, hq_name_special)\n",
    "\n",
    "#     df_teacher_behavior_res.to_csv(\"df_teacher_behavior_res.csv\", index=False)\n",
    "\n",
    "\n",
    "# 学生评价表中有些课程是floater的课程，需要与行为表课程对比删除（行为表无该情况）\n",
    "df_teacher_behavior_res_cache, df_teacher_behavior_processed_cache = teacher_behavior(\n",
    "                    start_time - DateOffset(years=5), end_time, df_teacher_behavior, \n",
    "                    class_type_name_special, hq_name_special)\n",
    "\n",
    "\n",
    "df_teacher_behavior_processed_cache = df_teacher_behavior_processed_cache[[\n",
    "                                    'awj_teacher_id', 'awj_lesson_id']]\n",
    "df_teacher_behavior_processed_cache['is_deleted'] = 'no'\n",
    "\n",
    "#     df_teacher_behavior_processed_cache.to_csv(\"df_teacher_behavior_cache_res.csv\", index=False)    \n",
    "\n",
    "\n",
    "\n",
    "######\n",
    "df_stu_comment_res, df_stu_comment_check = stu_comment(start_time, end_time, df_stu_comment, \n",
    "                class_type_name_special, hq_name_special, df_teacher_behavior_processed_cache)\n",
    "\n",
    "\n",
    "#     df_stu_comment_res.to_csv(\"df_stu_comment_res.csv\", index=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 下面还有一个地方对QC的函数进行了调用，因此得到的结果不准确，导致第一次QCtest的输出结果全部是错的\n",
    "\n",
    "# 宽表\n",
    "df_wide = pd.merge(df_teacher_info, df_teacher_behavior_res, on='awj_teacher_id', how='left')\n",
    "df_wide = pd.merge(df_wide, df_qc_res, on='awj_teacher_id', how='left')\n",
    "df_wide = pd.merge(df_wide, df_stu_comment_res, on='awj_teacher_id', how='left')\n",
    "\n",
    "#     df_wide.to_csv(\"df_wide_check.csv\", index = False)\n",
    "\n",
    "\n",
    "\n",
    "# 有些老师3个月内可能无qc分数，所以取历史qc记录处理后填补0分情况\n",
    "df_qc_all = teacher_qc_score(start_time - DateOffset(years=5), end_time, df_qc, \n",
    "                                         class_type_name_special, hq_name_special)\n",
    "df_qc_all = df_qc_all[['awj_teacher_id', 'teacher_score_max', \n",
    "                           'teacher_score_min', 'log_decay_score_mean']]\n",
    "df_qc_all.rename(columns={'teacher_score_max': 'teacher_score_max_all', \n",
    "                     'teacher_score_min': 'teacher_score_min_all', \n",
    "                     'log_decay_score_mean': 'log_decay_score_mean_all'}, inplace=True)\n",
    "df_wide = pd.merge(df_wide, df_qc_all, on='awj_teacher_id', how='left')\n",
    "# 有些老师没上过课，但请过假，此处为了让这些老师参加评分而非直接三星，所以将normal_lesson_log_count平滑处理\n",
    "df_wide.loc[(df_wide['normal_lesson_log_count'] == 0) & \n",
    "        (df_wide['ask_for_leave_log_count'] > 0), 'normal_lesson_log_count'] = math.log(2, 10)\n",
    "\n",
    "\n",
    "#     df_wide.to_csv(\"df_wide_res.csv\", index=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 衍生新字段\n",
    "df_wide['log_ask_for_leave/log_normal_lesson'] = df_wide['ask_for_leave_log_count'] / df_wide['normal_lesson_log_count']\n",
    "df_wide['abnormal_all_log_count'] = (df_wide['no_show_lesson_log_count'] + \n",
    "                                  df_wide['late_lesson_log_count'] + \n",
    "                                  df_wide['abnormal_lesson_log_count'] + \n",
    "                                  df_wide['ask_for_leave_log_count'])\n",
    "df_wide['abnormal_all_log_percent'] = (df_wide['abnormal_all_log_count']) / (\n",
    "                                  df_wide['normal_lesson_log_count'] + \n",
    "                                  df_wide['abnormal_all_log_count'])\n",
    "df_wide['lesson_time_range'] = ((end_time - df_wide['首课时间']).dt.total_seconds()) / (3600 * 24) \n",
    "df_wide.loc[df_wide['lesson_time_range'] == 0, \n",
    "    'lesson_time_range'] = ((end_time - df_wide['创建时间']).dt.total_seconds()) / (3600 * 24)  \n",
    "\n",
    "\n",
    "#     df_wide.to_csv(\"df_wide_final_res.csv\", index=False)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new teacher no: 0\n"
     ]
    }
   ],
   "source": [
    "##  在pycharm里面，因为后面的main要init两个函数，所以引用变成了两次，问题就出在这里\n",
    "# 见下面\n",
    "# 这个地方只能执行一次，不然会有key error\n",
    "# pycharm里面似乎有循环调用的嫌疑，所以报错了\n",
    "# 判断是否是新老师\n",
    "df_wide['old_new_teacher'] = 'old'\n",
    "df_wide.loc[(df_wide['首课时间'].isnull()) & \n",
    "            (df_wide['state'].isin(['oboard', 'active'])), 'old_new_teacher'] = 'new'\n",
    "# 缺失值填补\n",
    "# 无用字段去除\n",
    "df_wide.drop(['创建时间', '首次上架时间', '首课时间', 'state'], axis=1, inplace=True)\n",
    "columns = list(df_wide.columns)\n",
    "columns.pop(columns.index('awj_teacher_id'))\n",
    "columns.pop(columns.index('old_new_teacher'))\n",
    "# new teacher: mean\n",
    "for itm in columns:\n",
    "    df_wide.loc[df_wide['old_new_teacher'] == 'new', itm] = df_wide.loc[\n",
    "        (df_wide['normal_lesson_log_count'] > 0), itm].mean()\n",
    "# old teacher:0\n",
    "df_wide.fillna(value=0, inplace=True)\n",
    "new_teacher = df_wide.loc[df_wide['old_new_teacher'] == 'new', 'awj_teacher_id']\n",
    "print('new teacher no:', new_teacher.shape[0])\n",
    "# 有些老师没有请过假，advanced_days字段为0，填为均值\n",
    "df_wide.loc[(df_wide['ask_for_leave_log_count'] == 0) & (df_wide['normal_lesson_log_count'] > 0), \n",
    "    'advanced_days_max'] = df_wide.loc[(df_wide['advanced_days_max'] != 0) & \n",
    "                    df_wide['normal_lesson_log_count'] > 0, 'advanced_days_max'].mean()\n",
    "df_wide.loc[(df_wide['ask_for_leave_log_count'] == 0) & (df_wide['normal_lesson_log_count'] > 0), \n",
    "    'advanced_days_log_mean'] = df_wide.loc[(df_wide['advanced_days_log_mean'] != 0) & \n",
    "                    df_wide['normal_lesson_log_count'] > 0, 'advanced_days_log_mean'].mean()\n",
    "\n",
    "# df_wide.to_csv(\"judge_new_teacher_res.csv\", index=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 平滑\n",
    "# smooth0\n",
    "smooth = ['late_lesson_log_count', 'no_show_lesson_log_count', 'abnormal_lesson_log_count', \n",
    "          'ask_for_leave_log_count', \n",
    "          'stu_comment_log_bad_behavior']\n",
    "for itm in smooth:\n",
    "    df_wide[itm] = df_wide[itm] + math.log(2, 10)\n",
    "# 字段处理\n",
    "# 比例计算\n",
    "df_wide['late_lesson_log_percent'] = df_wide['late_lesson_log_count'] / df_wide['normal_lesson_log_count']\n",
    "df_wide['no_show_lesson_log_percent'] = df_wide['no_show_lesson_log_count'] / df_wide['normal_lesson_log_count']\n",
    "df_wide['abnormal_lesson_log_percent'] = df_wide['abnormal_lesson_log_count'] / df_wide['normal_lesson_log_count']\n",
    "df_wide['ask_for_leave_log_percent'] = df_wide['ask_for_leave_log_count'] / df_wide['normal_lesson_log_count']\n",
    "\n",
    "# df_wide.to_csv('smooth_0_res.csv', index=False)\n",
    "\n",
    "\n",
    "\n",
    "# smooth1\n",
    "# 老师异常行为有一项出现较大异常值时或整体较差，normal_lesson_log_count降为相应较低数值，整体表现变差\n",
    "counts = ['ask_for_leave_log_count', 'late_lesson_log_count', \n",
    "           'no_show_lesson_log_count', 'abnormal_lesson_log_count', \n",
    "           'abnormal_all_log_count']\n",
    "columns = ['ask_for_leave_log_percent', 'late_lesson_log_percent', \n",
    "           'no_show_lesson_log_percent', 'abnormal_lesson_log_percent', \n",
    "           'abnormal_all_log_percent']\n",
    "cache_columns = ['normal_lesson_log_count_processed_ask_for_leave_cahce1', \n",
    "                 'normal_lesson_log_count_processed_late_lesson_cache2', \n",
    "                 'normal_lesson_log_count_processed_no_show_cache3', \n",
    "                 'normal_lesson_log_count_processed_abnormal_lesson_cache4', \n",
    "                 'normal_lesson_log_count_processed_abnormal_all_cahce5'\n",
    "                ]\n",
    "for itm in cache_columns:\n",
    "    df_wide[itm] = df_wide['normal_lesson_log_count']\n",
    "df_wide['normal_lesson_log_count_processed'] = df_wide['normal_lesson_log_count']\n",
    "\n",
    "# 分位数\n",
    "quantiles = [[0.6, 0.7, 0.75, 0.8, 1], [0.8, 0.9, 0.92, 0.95, 1], \n",
    "            [0.5, 0.6, 0.66, 0.75, 0.8, 0.85, 0.9, 1], [0.8, 0.85, 0.9, 0.95, 1], \n",
    "            [0.55, 0.66, 0.75, 0.85, 1]]\n",
    "# 降低比例\n",
    "indexes = [[0.8, 0.6, 0.3, 0.1], [0.8, 0.7, 0.3, 0.1], \n",
    "          [0.8, 0.75, 0.6, 0.5, 0.3, 0.1, 0.03], [0.9, 0.85, 0.7, 0.3], \n",
    "          [0.8, 0.7, 0.3, 0.1]]\n",
    "for i in range(len(columns)):\n",
    "    for k in range(len(quantiles[i]) - 1):\n",
    "        standard1 = df_wide.loc[df_wide['normal_lesson_log_count'] > 0, \n",
    "                                columns[i]].quantile(quantiles[i][k])\n",
    "        standard2 = df_wide.loc[df_wide['normal_lesson_log_count'] > 0, \n",
    "                                columns[i]].quantile(quantiles[i][k + 1])\n",
    "        # 降低正常上课的数量\n",
    "        df_wide.loc[(df_wide['normal_lesson_log_count'] > 0) & \n",
    "            (df_wide[columns[i]] > standard1) & (df_wide[columns[i]] <= standard2), \n",
    "            cache_columns[i]] = df_wide['normal_lesson_log_count'] * indexes[i][k]\n",
    "        # 新老师因为平滑原因，所以再复原，不惩罚\n",
    "        df_wide.loc[(df_wide['normal_lesson_log_count'] > 0) & \n",
    "            (df_wide[columns[i]] > standard1) & (df_wide[columns[i]] <= standard2) & \n",
    "            (df_wide[counts[i]] == math.log(2, 10)) & \n",
    "            (df_wide['normal_lesson_log_count'] <= 8), \n",
    "            cache_columns[i]] = df_wide['normal_lesson_log_count']\n",
    "\n",
    "# df_wide.to_csv('smooth_1_res.csv', index=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# smooth_final\n",
    "# 从5行cache_colume中取最小值\n",
    "df_wide['normal_lesson_log_count_processed'] = df_wide[cache_columns].min(axis=1)\n",
    "# 大小方向统一化\n",
    "# 重新计算四个percent\n",
    "df_wide['late_lesson_log_percent_processed'] = df_wide['late_lesson_log_count'] / df_wide['normal_lesson_log_count_processed']\n",
    "df_wide['no_show_lesson_log_percent_processed'] = df_wide['no_show_lesson_log_count'] / df_wide['normal_lesson_log_count_processed']\n",
    "df_wide['abnormal_lesson_log_percent_processed'] = df_wide['abnormal_lesson_log_count'] / df_wide['normal_lesson_log_count_processed']\n",
    "df_wide['ask_for_leave_log_percent_processed'] = df_wide['ask_for_leave_log_count'] / df_wide['normal_lesson_log_count_processed']\n",
    "df_wide['normal_log_lesson_per_week'] = df_wide['normal_lesson_log_count_processed'] / (df_wide['lesson_time_range']) \n",
    "# 取倒数\n",
    "rcp = ['late_lesson_log_processed', 'no_show_lesson_log_processed', \n",
    "       'abnormal_lesson_log_processed', 'ask_for_leave_log_processed', \n",
    "       'stu_comment_log_bad_behavior_processed']\n",
    "cols = ['late_lesson_log_percent_processed', 'no_show_lesson_log_percent_processed', \n",
    "        'abnormal_lesson_log_percent_processed', 'ask_for_leave_log_percent_processed', \n",
    "        'stu_comment_log_bad_behavior']\n",
    "for i in range(len(rcp)):\n",
    "    df_wide[rcp[i]] = 1 / df_wide[cols[i]]\n",
    "\n",
    "# df_wide.to_csv('smooth_final_res.csv', index=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# fix_process_0\n",
    "# 修正老师上课数量少但好评较多的情况（如老师id642）\n",
    "columns = ['late_lesson_log_count', 'no_show_lesson_log_count', \n",
    "          'ask_for_leave_log_count', 'abnormal_lesson_log_count']\n",
    "no_smooths = ['late_lesson_log_count_no_smooth', 'no_show_lesson_log_count_no_smooth', \n",
    "          'ask_for_leave_log_count_no_smooth', 'abnormal_lesson_log_count_no_smooth']\n",
    "for i in range(len(columns)):\n",
    "    df_wide[no_smooths[i]] = df_wide[columns[i]]\n",
    "    df_wide.loc[df_wide[no_smooths[i]] == math.log(2, 10), no_smooths[i]] = 0\n",
    "df_wide['stu_comment_log_good_behavior_processed'] = df_wide['stu_comment_log_good_behavior'] / ( \n",
    "                            df_wide['normal_lesson_log_count']\n",
    "                            + df_wide['late_lesson_log_count_no_smooth'] \n",
    "                            + df_wide['no_show_lesson_log_count_no_smooth'] \n",
    "                            + df_wide['ask_for_leave_log_count_no_smooth'] \n",
    "                            + df_wide['abnormal_lesson_log_count_no_smooth'])                    \n",
    "df_wide['stu_comment_log_bad_behavior_processed'] = df_wide['stu_comment_log_bad_behavior'] / ( \n",
    "                            df_wide['normal_lesson_log_count'])\n",
    "\n",
    "\n",
    "# df_wide.to_csv('fix_process_0_res.csv', index=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# fix_process_1\n",
    "# 修正老师请假次数过多，但提前请假天数指标过好的情况（如老师id642） \n",
    "columns = ['advanced_days_log_mean', 'advanced_days_max']\n",
    "quantiles = [0.6, 0.66, 0.7, 0.75, 0.77, 0.8, 0.85, 1]\n",
    "indexes = [0.9, 0.8, 0.7, 0.5, 0.3, 0.1, 0.05]\n",
    "for i in range(len(columns)):\n",
    "    for k in range(len(quantiles) - 1):\n",
    "        percent1 = df_wide.loc[df_wide['normal_lesson_log_count'] > 0, \n",
    "                            'log_ask_for_leave/log_normal_lesson'].quantile(quantiles[k])\n",
    "        percent2 = df_wide.loc[df_wide['normal_lesson_log_count'] > 0, \n",
    "                            'log_ask_for_leave/log_normal_lesson'].quantile(quantiles[k + 1])\n",
    "        df_wide.loc[(df_wide['normal_lesson_log_count'] > 0) & \n",
    "                    (df_wide['log_ask_for_leave/log_normal_lesson'] > percent1) & \n",
    "                    (df_wide['log_ask_for_leave/log_normal_lesson'] <= percent2), \n",
    "                    columns[i]] = df_wide[columns[i]] * indexes[k]\n",
    "\n",
    "# df_wide = df_wide.round(5)\n",
    "# df_wide.to_csv('fix_process_1_res.csv', index=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# fix_process_final\n",
    "# 修正有些老师过去3个月内无qc，分数为0分的情况\n",
    "columns = ['log_decay_score_mean', 'teacher_score_min', 'teacher_score_max']\n",
    "for itm in columns:\n",
    "    df_wide.loc[(df_wide['normal_lesson_log_count'] > 0) & \n",
    "               (df_wide[itm].isin([np.nan, 0])), itm] = df_wide[itm + '_all']\n",
    "# 无上课记录老师\n",
    "columns = list(df_wide.columns)\n",
    "columns.pop(columns.index('awj_teacher_id'))\n",
    "for itm in columns:\n",
    "    df_wide.loc[df_wide['normal_lesson_log_count'] == 0, itm] = 0\n",
    "# 只取有行为数据的\n",
    "df_wide_final = df_wide.loc[df_wide['normal_lesson_log_count'] > 0]\n",
    "# get_df_wide_final\n",
    "# delete columns\n",
    "df_wide_final.drop(['advanced_days_std', 'teacher_score_std', \n",
    "              'advanced_days_min', 'lesson_time_range', 'old_new_teacher', \n",
    "              'teacher_qc_count', 'normal_lesson_log_count', 'late_lesson_log_count', \n",
    "              'no_show_lesson_log_count', 'abnormal_lesson_log_count', \n",
    "              'ask_for_leave_log_count', 'normal_log_lesson_per_week', \n",
    "              'stu_comment_log_good_behavior', 'stu_comment_log_bad_behavior', \n",
    "              'log_ask_for_leave/log_normal_lesson',  'abnormal_lesson_log_percent',\n",
    "              'late_lesson_log_percent', 'no_show_lesson_log_percent', \n",
    "              'ask_for_leave_log_percent', 'abnormal_all_log_count', \n",
    "              'late_lesson_log_percent_processed', 'no_show_lesson_log_percent_processed', \n",
    "              'abnormal_lesson_log_percent_processed', 'ask_for_leave_log_percent_processed', \n",
    "              'normal_lesson_log_count_processed', 'abnormal_all_log_percent', \n",
    "              'normal_lesson_log_count_processed_ask_for_leave_cahce1', \n",
    "              'normal_lesson_log_count_processed_late_lesson_cache2', \n",
    "              'normal_lesson_log_count_processed_no_show_cache3', \n",
    "              'normal_lesson_log_count_processed_abnormal_lesson_cache4', \n",
    "              'normal_lesson_log_count_processed_abnormal_all_cahce5',   \n",
    "              'log_decay_score_mean_all', 'teacher_score_max_all', 'teacher_score_min_all', \n",
    "              'stu_comment_log_bad_behavior_processed', \n",
    "              'late_lesson_log_count_no_smooth', 'no_show_lesson_log_count_no_smooth', \n",
    "              'ask_for_leave_log_count_no_smooth', 'abnormal_lesson_log_count_no_smooth'], axis=1, inplace=True)\n",
    "# save\n",
    "# df_wide_final = df_wide_final.round(5)\n",
    "# df_wide_final.to_csv('gen_df_wide_final_res.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['awj_teacher_id', 'advanced_days_log_mean', 'advanced_days_max',\n",
       "       'teacher_score_max', 'teacher_score_min', 'log_decay_score_mean',\n",
       "       'late_lesson_log_processed', 'no_show_lesson_log_processed',\n",
       "       'abnormal_lesson_log_processed', 'ask_for_leave_log_processed',\n",
       "       'stu_comment_log_good_behavior_processed'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_wide_final.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 因子载荷矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fa_index1</th>\n",
       "      <th>fa_index2</th>\n",
       "      <th>fa_index3</th>\n",
       "      <th>fa_index4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.062063</td>\n",
       "      <td>-0.028543</td>\n",
       "      <td>0.530873</td>\n",
       "      <td>0.008978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.087088</td>\n",
       "      <td>-0.017771</td>\n",
       "      <td>0.545701</td>\n",
       "      <td>-0.019414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.027714</td>\n",
       "      <td>0.344296</td>\n",
       "      <td>-0.032156</td>\n",
       "      <td>0.028113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.036995</td>\n",
       "      <td>0.346024</td>\n",
       "      <td>-0.001726</td>\n",
       "      <td>-0.060828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.032262</td>\n",
       "      <td>0.358875</td>\n",
       "      <td>-0.021149</td>\n",
       "      <td>-0.026614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.294944</td>\n",
       "      <td>-0.023287</td>\n",
       "      <td>-0.051459</td>\n",
       "      <td>-0.005215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.324883</td>\n",
       "      <td>-0.028596</td>\n",
       "      <td>-0.071127</td>\n",
       "      <td>0.020754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.321721</td>\n",
       "      <td>-0.017894</td>\n",
       "      <td>-0.087450</td>\n",
       "      <td>0.007256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.275466</td>\n",
       "      <td>-0.043566</td>\n",
       "      <td>-0.015902</td>\n",
       "      <td>0.034857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.023129</td>\n",
       "      <td>-0.028920</td>\n",
       "      <td>-0.006686</td>\n",
       "      <td>1.000274</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fa_index1  fa_index2  fa_index3  fa_index4\n",
       "0  -0.062063  -0.028543   0.530873   0.008978\n",
       "1  -0.087088  -0.017771   0.545701  -0.019414\n",
       "2  -0.027714   0.344296  -0.032156   0.028113\n",
       "3  -0.036995   0.346024  -0.001726  -0.060828\n",
       "4  -0.032262   0.358875  -0.021149  -0.026614\n",
       "5   0.294944  -0.023287  -0.051459  -0.005215\n",
       "6   0.324883  -0.028596  -0.071127   0.020754\n",
       "7   0.321721  -0.017894  -0.087450   0.007256\n",
       "8   0.275466  -0.043566  -0.015902   0.034857\n",
       "9   0.023129  -0.028920  -0.006686   1.000274"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FA_indexs\n",
    "fa_index = pd.read_excel(path + 'fa_indexs.xlsx')\n",
    "fa_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "fa_index = fa_index.as_matrix()\n",
    "df_wide_matrix = deepcopy(df_wide_final)\n",
    "df_wide_matrix.drop(['awj_teacher_id'], axis=1, inplace=True)\n",
    "df_wide_matrix = df_wide_matrix.as_matrix()\n",
    "# df_wide标准化\n",
    "df_wide_matrix = preprocessing.scale(df_wide_matrix)\n",
    "# 每个老师的各因子得分\n",
    "fa_score = np.dot(df_wide_matrix, fa_index)\n",
    "# 主成分贡献率\n",
    "var = np.array([[0.39025 / 0.87332], \n",
    "                [0.23851 / 0.87332], \n",
    "                [0.14904 / 0.87332], \n",
    "                [0.09552 / 0.87332]])\n",
    "# 每个老师的最终得分\n",
    "final_score = np.dot(fa_score, var)\n",
    "# df格式\n",
    "teacher_fa_score = np.hstack((fa_score, final_score))\n",
    "teacher_fa_score = pd.DataFrame(teacher_fa_score)\n",
    "teacher_fa_score['awj_teacher_id'] = list(df_wide_final['awj_teacher_id'])\n",
    "teacher_fa_score.rename(columns={0: 'teacher_behavior_score', 1: 'teacher_qc_score', \n",
    "                                 2:'teacher_attitude_score', 3: 'student_comment_score', \n",
    "                                 4: 'final_score'}, inplace=True)\n",
    "# 星级映射(去除过去一段时间周期内没上过课的老师)\n",
    "teacher_fa_score = teacher_fa_score.sort_values(by='final_score', ascending=0)\n",
    "\n",
    "# teacher_fa_score = teacher_fa_score.round(5)\n",
    "# teacher_fa_score.to_csv(\"gen_fa_score_dataframe_res.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 业务要求的分位数\n",
    "star_5 = teacher_fa_score['final_score'].quantile(0.8)\n",
    "star_4 = teacher_fa_score['final_score'].quantile(0.5)\n",
    "star_3 = teacher_fa_score['final_score'].quantile(0.2)\n",
    "star_2 = teacher_fa_score['final_score'].quantile(0.1)\n",
    "teacher_fa_score.loc[teacher_fa_score['final_score'] <= star_2, 'star'] = 1\n",
    "teacher_fa_score.loc[(teacher_fa_score['final_score'] > star_2) & \n",
    "                     (teacher_fa_score['final_score'] <= star_3), 'star'] = 2\n",
    "teacher_fa_score.loc[(teacher_fa_score['final_score'] > star_3) & \n",
    "                     (teacher_fa_score['final_score'] <= star_4), 'star'] = 3\n",
    "teacher_fa_score.loc[(teacher_fa_score['final_score'] > star_4) & \n",
    "                     (teacher_fa_score['final_score'] <= star_5), 'star'] = 4\n",
    "teacher_fa_score.loc[teacher_fa_score['final_score'] > star_5, 'star'] = 5\n",
    "\n",
    "# teacher_fa_score = teacher_fa_score.round(5)\n",
    "# teacher_fa_score.to_csv(\"gen_star_rate_res.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 拼回去\n",
    "teacher_fa_score = pd.merge(teacher_fa_score, df_wide[\n",
    "    ['awj_teacher_id', 'normal_lesson_log_count']], on='awj_teacher_id', how='right')\n",
    "teacher_fa_score.fillna(value=0, inplace=True)\n",
    "teacher_fa_score.to_csv(path + 'teacher_star.csv', sep=',', \n",
    "                        float_format='%.5f', encoding='utf-8', index=False)\n",
    "\n",
    "# teacher_fa_score = teacher_fa_score.round(5)\n",
    "# teacher_fa_score.to_csv(\"gen_final_table_res.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
